\chapter{High-throughput morphometric analyses of endothelial organelles}
\label{endothelial_morphometry}
\ifpdf
	\graphicspath{{chapter_2/figs/}}
\fi

\nomenclature[z-WPB]{$WPB$}{Weibel-Palade body}
\nomenclature[z-WPB]{$HUVEC$}{Human Umbilical Vein Endothelial Cell}
\nomenclature[z-WPB]{$SVM$}{Support Vector Machine}
\nomenclature[z-CSR]{$CSR$}{Complete Spatial Randomness}

High-throughput microscopic surveys of endothelial organelles from primary human umbilical vein endothelial cells (HUVECs) are invaluable to the study of both inflammatory and haemostatic processes. Large scale analyses fluorescently labelled organelles are sensitive at detecting subtle phenotypes in populations. Phenotypic characteristics are measured by the numbers of organelles and their morphometric features. Analysis of endothelial organelles may be performed at a population or on a per-cell basis, depending on the biological question being addressed. In high-throughput surveys, altering the cellular conditions with secretagogue and drug treatments can be used to infer biological function and processes.

The endothelial storage organelles Weibel-Palade bodies (WPBs) are of particular interest, due to their critical role in initial haemostasis and inflammation. A principle cargo of WPBs is the large multimeric protein von Willebrand Factor (vWF). Fluorescent labelling of WPBs by their vWF molecular cargo, allows for studies of the biological function of WPBs, including, the study of mechanisms of WPB exocytosis. This is investigated by performing morphometric analysis of vWF at the external endothelial cell surface.

An abundance of fluorescence imaging data is generated in high-throughput surveys of endothelial organelles. For such large scale datasets automated analysis is the only viable approach to extract meaningful quantitative data. This chapter describes methods of image segmentation and feature collection employed for the large scale quantitative morphometric analyses of endothelial organelles. Methods and techniques for exploration, analysis, and visualisation of the resulting data are also discussed.

\section{Introduction}
\label{endothelial_morphometry:introduction}
Visual inspection of cells under a microscope is a basic yet fundamental technique in cell biology. Traditionally, experimental data from microscopy would be measured and assessed by a trained biologist. The human visual system is adept at intuitively interpreting visual information, and endowed with the ability to filter irrelevant variations in illumination and contrast. Recent advances in optical technologies and instrumentation are providing previously unimagined capabilities. Robotic microscopy and modern immunostaining techniques have increased the speed and capacity to gather microscopic image data from experiments. This has served to amplify the utility and necessity of visual inspection and measurement of cells. Expert manual inspection and annotation is not feasible for detection of subtle cell population differences over tens or hundreds of thousands of cells. Visual analysis has therefore become a bottleneck in performing large image-based high-throughput screens. To address this, advances in bioinformatics and high-throughput computational automated analysis tools have been developed to extract quantitative information from microscopy images.

Automated image analysis does provide some substantial benefits over manual scoring, including: providing unbiased highly quantitative scoring, highly reproducible, able to detect subtle population differences, is fast, eliminates tedious manual labour and is able to simultaneously collect multiple features~\cite{Jones2006}. In high-throughput endothelial surveys a wide variety of features were collected on a population and per-cell basis, since a priori it is not known which measurements will be most useful or interesting. Collection of a large number of features also provides the most freedom in data analysis.

Quantitative measurements in fluorescence microscopy contain some amount of error, this may be introduced by the specimen, the microscope or the detector. To minimise sources of error, in high-throughput morphometry of endothelial organelles requires consideration of, both the image processing and experimental design. The imaging system should be configured for optimal signal detection, low background and low noise. Acquired images should be in focus over the full dynamic range of the camera whilst avoiding pixel saturation. To maintain pixel values digital files must be stored in original raw format or using lossless compression.

To ensure optimal data careful consideration of the experimental phase, acquisition phase, and image processing approach must be carefully considered. Through multiple trials with various anti-bodies, microscope settings and image segmentation techniques an optimal experimental workflow can be achieved. This chapter details the developments of image segmentation  for high-throughput morphometric analyses of endothelial organelles.

\subsubsection{Experimental workflow}
A general approach to experimentation in life sciences is to investigate defined research questions or hypotheses, via quantitative analyses of experimental data. A single experiment or a series of experiments may be constructed to investigate a hypothesis. For a hypothesis to be accepted, results must be reproducible over multiple experiments and corroborated by alternative experimental methods. This approach of experimentation, interpretation and re-experimentation is effective when applied to high-throughput morphometric analyses of endothelial organelles.

The experimental loop displayed in Figure~\ref{figure:endothelial_morphometry:introduction:experimental_workflow} shows typical stages in experiment design and analysis. The top row of processes deals with the biological hypothesis and experimental setup, whilst the bottom row of processes are relating to data analysis and interpretation of the results. The first step in the loop is specification of a hypothesis, followed by: defining experimental groups to test the hypothesis, assignment of samples to those groups and preparation of the specimen. The bottom row of processes converts the raw data into a form that can quantitatively address the initial hypothesis. Collection of data, aggregation of data and additional analysis allows for interpretation of the data. Typically, investigation of a hypothesis leads to investigation of further hypotheses and the loop is self-perpetuating.

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=1.0\textwidth]{experimental_workflow}
	\caption[Experimental workflow in life science imaging]{A general experimental workflow in life science imaging. Adapted from Prodanov and Verstreken, 2012~\cite{Prodanov2012}}
	\label{figure:endothelial_morphometry:introduction:experimental_workflow}
\end{figure}

At each step in the processing workflow in Figure~\ref{figure:endothelial_morphometry:introduction:experimental_workflow} the volume of output data is decreased, with a corresponding increase in the complexity of generated information or derived data. For example, acquired images of cells can be transformed into a set of morphometric and intensity features. Each feature has a different semantic context, such as: nucleus area or cell perimeter. In the acquired raster images of cells the biological object is only implicitly present, but in the derived data the biological object is explicitly constructed. The explicit information contained within the raster image for example about staining distribution and illumination is lost. The process of object segmentation and feature extraction is therefore accompanied by irreversible reduction of the input information. At each step in the workflow the information in the previous step is transformed into contextual data, called metadata. The information complexity increase is thereby also mapped to an increase of the complexity of the data structure~\cite{Prodanov2012}.

For example the extraction of morphometric and pixel intensity measurements leads to a reduced representations of the image features of interest. These features have higher information complexity compared to the raw data, but there is an irreversible information loss by the process of measurement. To replicate the measurements from the original data, the same image processing algorithms must be applied. Therefore, measurements are only implicitly present in images~\cite{Prodanov2012}.

\subsubsection{Morphological image processing}
In a biological context morphology refers to the study of form and structure of an organism. The mathematical context of morphology is as a tool for extracting image components that are of use in representation of region shape. In morphological image processing the inputs are images but the outputs are attributes extracted from those images.

Morphometric analyses of endothelial organelles sets out to obtain features relating to the shape and pixel intensity of organelles. A number of steps were performed in order to extract morphological features, from endothelial cell images. Typically, images may be pre-processed to reduce noise and enhance the contrast between certain features. Different segmentation approaches will be attempted and parameters optimised to subdivide the image into its constituent regions or objects. A binary mask of the relevant segmented objects can then be used to measure properties of the labeled image regions. Properties include morphometry and with reference to the original image pixel intensity information. The resulting measurements can be combined and evaluated statistically to infer biological meaning.

\section{Image acquisition}
\label{endothelial_morphometry:image_acquisition}
Analyses of endothelial organelle morphometry were performed on confocal microscopy images acquired with separate staining of cellular organelles. DNA in cell nuclei were fluorescent stained with non-antibody methods and additional organelles were stained with immunofluorescence antibody methods. In a typical experiment, 9 fields of view were imaged per microtitre well, generating datasets of 864 images and approximately 10000 complete endothelial cells. The volume of data collected can easily be scaled up by imaging more fields of view per well, without more labour intensive laboratory work.

Human umbilical vein endothelial cells (HUVECs) were imaged on an Opera high-content screening (PerkinElmer) confocal microscope. The HUVECs were cultured, fixed and immunostained in 96-well microtitre plates and imaged using a 40$\times$ air objective lens (numerical aperture of 0.6). At 40$\times$ magnification the width and height of each pixel in the obtained images corresponds to a physical width and height of \SI{0.1612}{\micro\meter}. Morphometric measurements can thus easily be converted from pixel sizes to dimensions in micrometers.

The resolving power or resolution limit of the optical system is defined as the minimum distance apart of two objects in order for them to be resolved as separate objects. This distance is equal to the smallest point source in the image, and is given by Abbe's equation~\cite{Abbe1873},
\begin{equation}
r=0.61\frac{\lambda}{NA},
\end{equation}
where, $r$ is the resolution limit, $\lambda$ is the wavelength and $NA$ the numerical aperture of the optical system.

The Opera confocal microscope has an available excitation wavelength range from \SIrange{488}{640}{\nano\meter}, with a numerical aperture of 0.6, this gives a minimum resolvable resolution range from \SIrange{496}{650}{\nano\meter}. The smallest resolvable structures in the images obtained are therefore between 2 and 4 pixels in length, depending on the channel being imaged.

In high-throughput analyses the endothelial organelles that are frequently stained are nuclei, plasma membrane, WPB ,and external vWF, examples of which are displayed in Figure~\ref{figure:image_acquisition}. The hypothesis being tested dictates the experimental setup and the specific cell organelles that are immunostained and imaged. Invariably, vWF is immunostained and imaged as a marker exocytic sites or for internal WPBs. Cell nuclei are always imaged, and additional staining could cell plasma membrane for single cell analysis. PerkinElmer's Opera high throughput confocal microscope allows for a maximum of 4 channels to be imaged per experiment. Along with the vWF channel, two channels are required for accurate cell segmentation, namely, the nuclei and plasma membrane channel. This leaves the last channel that can be used to stain for additional organelles or left empty. The resulting image data is combined as a set of images each with multiple channels, in a 16-bit TIFF format.

\begin{figure}[htbp]\centering
	\begin{subfigure}[b]{0.49\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{image_acquisition_nuclei}
		\caption{}
		\label{figure:image_acquisition:nuclei}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{image_acquisition_plasma_membrane}
		\caption{}
		\label{figure:image_acquisition:plasma_membrane}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\linewidth} %001005004.tif from 151113_Jess_TC_CCE_Rep2
		\begin{tikzpicture}[spy using outlines={square,red,magnification=3,size=3cm, connect spies}]
		\node[anchor=south west,inner sep=0]  at (0,0) {\includegraphics[width=\textwidth]{image_acquisition_wpb}};
		\spy [every spy on node/.append style={ultra thick}] on (4.7,4.0) in node [left] at (3.3,5.4);
		\end{tikzpicture}
		\label{figure:image_acquisition:wpb}
		\caption{}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\linewidth} %001005004.tif from 151113_Jess_TC_CCE_Rep2
		\begin{tikzpicture}[spy using outlines={rectangle,red,magnification=3,size=3cm, connect spies}]
		\node[anchor=south west,inner sep=0]  at (0,0) {\includegraphics[width=\textwidth]{image_acquisition_exit_sites}};
		\spy [every spy on node/.append style={ultra thick}] on (2.7,4.0) in node [left] at (7.4,5.4);
		\end{tikzpicture}
		\label{figure:image_acquisition:exit_sites}
		\caption{}
		\vspace{1ex}
	\end{subfigure}
\caption[Image acquisition examples]{Example images acquired in a high-throughput study of endothelial cells, acquired with four channels. Image (a) is the nuclei stained channel, image (b) are stained plasma membrane, image (c) are Weibel-Palade bodies (WPB) stained, and image (d) is stained for exocytosed von Willebrand factor (vWF).}
\label{figure:image_acquisition}
\end{figure}

\subsubsection{Staining}
External or exocytosed vWF were labelled at the cell surface to study mechanisms of exocytosis. Cell nuclei are stained either by Hoechst or DAPI (4',6-diamidino-2-phenylindole) dyes, which bind to tightly packed AT-rich regions of DNA in chromosomes within the nucleus, making an effective nuclear stain.

Immunostaining of vWF within WPBs involves the use of a primary and a secondary antibody. Over multiple experiments different antibodies have been trialled for this purpose. A Dako rabbit anti-vWF polyclonal primary antibody, is an antiserum that has many different antibodies that recognise different portions of the vWF protein, since it is produced using whole vWF isolated from human plasma to immunise the rabbit. In fixed HUVECs, the Dako antibody will bind to the vWF that is in WPBs but will also bind to the unprocessed vWF that is in the endoplasmic reticulum (ER). The ER is a mesh-like structure that extends over the interior of the cell, the ER staining may overlap with the WPB staining and make it difficult to identify WPB against the ER.

To overcome the ER interference problem, a secondary rabbit anti-propeptide polyclonal antibody is used. This is a rabbit antibody from rabbits that were injected with a synthetic 8 amino acid peptide sequence (SSPLSHRS) that is found at the end of the proregion of vWF after it has been processed. This sequence is not available for antibodies to bind to it in the unprocessed ER form of vWF, so as a result, the antibodies will only bind to the vWF in WPBs.

Immunostaining of exocytosed vWF was performed with a number of steps. Cells were washed several times in serum-free medium, the Dako rabbit anti-vWF polyclonal antibody was added along with a secretagogue. After stimulation with a secretagogue the cells are fixed and permeabilised, a secondary sheep vWF antibody is added. An antibody conjugated to 647 fluorophore that recognises the Dako rabbit, to stain the Dako vWF that was initially fed to the cells. This vWF is visible on the cell surface. When the medium is removed before fixation the antibody that is not bound is also removed. A further antibody conjugated to 488 fluorophore is used to see the internal vWF. Cell nuclei are immunostained either by Hoechst or DAPI (4',6-diamidino-2-phenylindole). 

The cell plasma membrane is stained either by anti-VE-Cadherin antibodies or fluorophore-conjugated wheat germ agglutinin (WGA). Anti-VE-Cadherin is an antibody specific for VE-Cadherin, which is a cell-cell adhesion glycoprotein found in between endothelial cells~\cite{Vestweber2008}. It is important for holding endothelial cells together with their neighbour cells to form a tight barrier. WGA is a member of the lectin family that binds to N-acetyl-D-glucosamine and sialic acid residues found on the surface of cell membranes, that has been used extensively to stain surface membranes.

\section{Image processing}
\label{endothelial_morphometry:image_processing}
Image processing was performed in Python with extensive use of the scikit-image~\cite{VanderWalt2014} and scikit-learn~\cite{Pedregosa2011} libraries. A generalised image processing approach was created that is customisable to the specific experimental setup. Functionality is included to choose the appropriate segmentation method depending on the channels imaged and their configuration. If a plasma membrane and nuclei stain were present then analysis includes a cell assignment step, to allow for single cell analysis. Cellular segmentation requires the presence of both a nuclei and a plasma membrane channel, where nuclei are used as seed points to identify cells.

The Python code was structured such that it is readable and adjustable by non-experts, with the minimum number of parameters and alteration between experiments. It is a generally applicable framework for segmentation of endothelial organelles in various channel combinations and imaging modalities. Adjustable variables and parameters are in the head of the code including the channel configuration, image processing parameters, and images to exclude. Acquired images of insufficient quality may be excluded from analysis as described in section~\ref{figure:image_processing:quality_control}. Each organelle segmentation method was written as a separate function, which takes the input image and performs segmentation, returning found contours and a set of features.

A for loop processes each image in a dataset sequentially and outputs image segmentation contours overlays and morphological results tables. An overlay of segmentation contours allows the segmentation result to be checked visually to ensure it is accurate. On each iteration of the loop results are appended to the results tables and written to disk, to reduce the computer memory usage. An iterative approach although slower, is advantageous over batch processing because it has lower memory requirements, debugging is easier and multiple plates can be run simultaneously. Segmented objects are also printed to the console as a way for the user to ensure the results are reasonable, for example \emph{Analysing 001001004.tif, image 4 of 864, detected: 22 nuclei, 7 cells, 1794 wpb}. These outputs also act as a quick method for the user to determine whether the segmentation is reasonable, depending on whether realistic outputs are given.

The flowchart in Figure~\ref{figure:image_processing:flowchart} presents each step in the image processing pipeline for segmentation and feature extraction of four image channels. There are some dependencies between channels, for example the plasma membrane channel is dependent on an input from the nucleus channel as the nucleus acts as a seed for the cell. The WPB channel is dependent on an input form the plasma membrane channel to assign a WPB to it's constituent cell. Channels are processed in an order relative to these dependencies, such that the nucleus channel is processed first, followed by the plasma membrane channel and then other cell organelles, and finally organelles are assigned to their respective cells.

\begin{landscape}
\begin{figure}
	\centering
	\includegraphics[height=0.8\textwidth]{flowchart/image_processing_flowchart}
	\caption[Flowchart of segmentation processes of endothelial organelles]{Flowchart of segmentation and feature extraction processes of endothelial organelles, including nucleus, cells, Weibel-Palade body (WPB) and exocytosed von-Willebrand factor (vWF). Dark ellipses in the flowchart are significant intermediary images and rectangles with rounded corners show the image processing steps.}
	\label{figure:image_processing:flowchart}
\end{figure}
\end{landscape}

\subsubsection{Region properties}
\label{endothelial_morphometry:morphometric_measurements}
The scikit-image library~\cite{VanderWalt2014} in Python contains a \emph{regionprops} function to measure properties of labelled image regions. Supplying a labelled image and the original intensity image allows for measurements of morphometric features and pixel intensity measurements. The \emph{regionprops} function was used for measurement of morphometric and pixel intensity features in the analysis of endothelial organelles. Pixel intensity and morphometric measurements are taken for every segmented nucleus, cell and WPB or exocytic site in a high-throughput survey. Although the \emph{regionprops} command provides a multitude of outputs, only the most pertinent single value attributes were extracted from the region properties. A list with descriptions of the measured attributes is displayed in Table~\ref{table:endothelial_morphometry:region_properties}. The row, column and field of view for each segmented particle are obtained from the filename of the image, for example a file '003002001.tif`, was imaged from microtitre plate row 3, column 2 and field of view 1. If cellular segmentation was performed then the labelled cell number is also returned. 

\begin{table}[htbp]
\caption{Terminology and descriptions, for each segmented object in a high throughput survey, consisting of meta-data to identify the object, morphometric measurements and intensity measurements. The \emph{particle\_id, row, coll, fov} are obtained from the filename of the input image.}
\centering
\label{table:endothelial_morphometry:region_properties}
\begin{tabular}{l p{9cm}}
    \toprule
    Attribute  & Description \\
    \midrule
    particle\_id        & The id of the cell from which the measurement was taken, consisting of a row number, column number, field of view number and cell number \\
    row                 & The microtitre row number from which the image was taken \\
    col                 & The microtitre column number from which the image was taken \\
    fov                 & The image field of view number \\
    cell                & The cell label number of the object \\
    x\_centroid         & The centroid of the region in the x-axis \\
    y\_centroid         & The centroid of the region in the y-axis \\
    area                & The area of the region \\
    perimeter           & The perimeter of the region. \\
    feret               & The longest distance between any two points along the region boundary, also known as maximum caliper \\
    equivalent diameter & The diameter of a circle with the same area as the region \\
    convex\_area        & Area of the convex hull of the region \\
    major\_axis\_length & The length of the major axis of the ellipse that has the same normalized second central moments as the region \\
    minor\_axis\_length & The length of the minor axis of the ellipse that has the same normalized second central moments as the region \\
    orientation         & Angle between the X-axis and the major axis of the ellipse that has the same second-moments as the region. Ranging from -pi/2 to pi/2 in counter-clockwise direction \\
    solidity            & Ratio of area in the region to area of the convex hull image \\
    max\_intensity      & Pixel value with the greatest intensity in the region \\
    min\_intensity      & Pixel value with the greatest intensity in the region \\
    
    mean\_intensity     & Pixel value with the greatest intensity in the region \\
    \bottomrule
\end{tabular}
\end{table}

One feature of particular importance that was not available in the \emph{regionprops} function was a measure of the Feret diameter. The maximum Feret diameter or the maximum caliper diameter is the distance between the most separated points of the region boundary. This has previously been identified as a descriptive feature for morphometric analyses of WPBs~\cite{Ferraro2014}.

A function was written to calculate the Feret diameter of each region, see listing~\ref{listing:feret_function}. The function takes a set of coordinates and returns the maximum euclidean distance between the pixels. Since the maximum Feret diameter must be between pixels on the region edge, the region properties function was first used to return a list of pixel coordinates on the boundary of a region. This coordinate list is then passed to the \emph{calculateFeret} function. The distance between each pixel and every other pixel is calculated, and the maximum distance returned in line 2. A scaling factor is applied in line 3 to account for Feret measurements being from the centre of a pixel to the centre of another pixel, this is to correspond with the Feret diameter measurements in ImageJ~\cite{ImageJ2003}.
\begin{lstlisting}[
	style=python,
	label={listing:feret_function},
	caption={Python function for calculation of the Feret diameter}
	]
def calculateFeret(coordinates):
    feret = np.nanmax(squareform(pdist(coordinates)))
    feret = feret + (((2*((0.5)**2))**(0.5))*2)
    return feret
\end{lstlisting}
All measurements in Table~\ref{table:endothelial_morphometry:region_properties} can be converted into units corresponding to the physical size of the object, by applying a scaling factor. The scaling factor is a multiplier that maps the morphological measurements in pixels to a size in microns, or for the area microns squared. The user is able to adjust the scaling factor relevant for the imaging setup.

\subsubsection{Data quality control}
\label{endothelial_morphometry:image_processing:quality_control}
Prior to performing image analysis a step was performed to identify and remove unsuitable images from each dataset. Images maybe of inadequate quality due to fluorescence artifacts or problems in the microscope acquisition. Fluorescence artifacts can result from bleed-through, or non-specific staining for example. Problems with the microscope acquisition are manifest as very dark images, washed out noisy images, or large amorphous bright regions within an image. Figure~\ref{figure:image_processing:quality_control} shows some examples of images that should be removed from further processing. This stage is  useful to ensure that the raw images are assessed prior to analysis. It is useful to check the consistency of data over a large image set.

\begin{figure}[htbp]\centering
	\begin{subfigure}[b]{0.49\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{quality_control_1}
		\caption{}
		\label{figure:image_processing:quality_control_1}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{quality_control_2}
		\caption{}
		\label{figure:image_processing:quality_control_2}
		\vspace{1ex}
	\end{subfigure}
\caption[Excluded images]{Images that are unusable and have been excluded from further processing, by a manual inspection of images with high and low mean pixel values. Image (a) is occluded by debris or dirt and image (b), is symptomatic a laser malfunction on the microscope.}
\label{figure:image_processing:quality_control}
\end{figure}

A crude but effective approach to identify images of an insufficient standard in a dataset is to, sort all images in each image channel by their image mean pixel values. Sorting of image stacks was achieved using the ImageJ stack sorter plugin~\footnote{B. Dougherty, Stack Sorter ImageJ Plugin, \url{http://www.optinav.com/Stack-Sorter.htm}, accessed 2015-09-14}. The images at the extremes of high and low intensity can then be assessed by the user to see whether they are appropriate for further analysis. Typically, problem images in a dataset are at the extremes of high or low mean pixel values. Images can then be removed from further data processing, to ensure consistent results.

In Python all files in the specified image directory are found and a set object is created. The user specifies a list of images to exclude, a second set is created from this list of images to be excluded. The exclusion set is subtracted from the set of all the images in the directory, and the result is sorted. In this way images can be removed from processing.

\subsection{Nucleus segmentation}
\label{endothelial_morphometry:image_processing:nuclei}
Segmentation of nuclei was the first stage in morphometric analysis of endothelial cells. It forms the basis of cellular segmentation because nuclei are used as seed points or cell markers. Correct identification and segmentation of nuclei is fundamental to cellular segmentation, and therefore the assignment of endothelial organelles to their constituent cells. The consistently high quality staining of the DAPI and Hoechst fluorescent dyes over many experiments, has lead to the development of a stable optimised nuclei segmentation routine that does not need adjusting between experiments. Figure~\ref{figure:image_processing:flowchart} outlines each step in the segmentation pipeline, and the major stages of nuclei segmentation are demonstrated visually in Figure~\ref{figure:image_processing:nuclei_segmentation}.

\begin{figure}[htbp]\centering
	\begin{subfigure}[b]{0.25\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{nuclei_section_00_original}
		\caption{}
		\label{figure:image_processing:nuclei_segmentation:00}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.25\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{nuclei_section_01_otsu}
		\caption{}
		\label{figure:image_processing:nuclei_segmentation:01}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.25\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{nuclei_section_02_hole_fill}
		\caption{}
		\label{figure:image_processing:nuclei_segmentation:02}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.25\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{nuclei_section_03_watershed}
		\caption{}
		\label{figure:image_processing:nuclei_segmentation:03}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.25\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{nuclei_section_04_svm}
		\caption{}
		\label{figure:image_processing:nuclei_segmentation:04}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.25\linewidth} %001001001.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{nuclei_section_05_contours}
		\caption{}
		\label{figure:image_processing:nuclei_segmentation:05}
		\vspace{1ex}
	\end{subfigure}
\caption[Nuclei segmentation]{The major sequence of processes involved in segmentation of nuclei. Image (a) is the raw image, (b) after applying Otsu's threshold, (c) following a binary hole fill, (d) depicts the watershed transform, and (e) is after a classification step, finally image (f) shows a quality control image output with segmentation contours. The red box in images (a) and (b) highlights the effect of binary hole filling, the green box in images (c) and (d) shows the watershed transform, and the yellow box in images (d) and (e) highlights the result of classification.}
\label{figure:image_processing:nuclei_segmentation}
\end{figure}

\subsubsection{Thresholding}
The first step in segmentation of nuclei applies an intensity threshold to the image to create a binary image (see Figure~\ref{figure:image_processing:nuclei_segmentation:01}), separating foreground and background objects. A variety of thresholding methods were trialled for this purpose, and Otsu's method was found to give by eye accurate segmentation contours over a sample of images. Otsu's method~\cite{Otsu1979} is a widely used thresholding technique that calculates a threshold by maximising the variance between two classes of pixels, and was found to be very effective at segmenting objects in the nuclei images.

\subsubsection{Binary hole fill}
The mottled nature of nuclei staining and variation in staining across an image can lead to holes in thresholded foreground objects, as shown by the red box in Figure~\ref{figure:image_processing:nuclei_segmentation}. These holes are problematic since they can lead to inaccuracy in morphological measurement, specifically in the measurement of area. Holes that may occur in segmented objects along the image border are particularly troublesome. Holes on the border in later processing with the watershed transform can result in incorrect splitting of a region into multiple objects. The existing algorithm in Python for binary hole filling provided by SciPy~\footnote{Jones E., Oliphant E., Peterson P., et al. SciPy: Open Source Scientific Tools for Python, 2001-, \url{http://www.scipy.org/} accessed 2016-04-26} has the limitation that it does not fill holes in objects on the image border, since holes on the image border are not surrounded completely by a connected border of foreground pixels. To overcome this a custom binary hole filler was implemented on the assumption that the background area is always larger than the largest foreground connected component. This assumption should always hold in correctly acquired nuclei images. The hole filler algorithm extracts the background region by performing a connected component analysis on the image. All other pixels, that are not part of that connected component are set to foreground pixels. The result of applying the binary hole filler is exemplified by the red box in Figures~\ref{figure:image_processing:nuclei_segmentation:01} and~\ref{figure:image_processing:nuclei_segmentation:02}.

\subsubsection{Watershed transform}
The watershed transform is a versatile and commonly applied region based segmentation algorithm~\cite{Vincent1991}. It takes its name from an analogy with hydrology, where watershed lines are the divisions in a landscape splitting an area into catchment basins. The concept of watershed basins can be visualised as the domains of attraction for rain falling over a region, or alternatively, consider a landscape being submerged in a lake, basins will fill with water and at points where water from different basins meet, dams are built~\cite{Roerdink2000}. In extending this idea to digital images, we can consider that an image has a topographic relief dictated by its pixel values, moreover catchment basins in this relief can be found, and the lines dividing these basins are watershed lines. In the case of nuclei segmentation a watershed transform was used to separate nuclei that are close, overlapping, or touching. The application of a watershed can be observed by the splitting of the objects in the green boxes in Figure~\ref{figure:image_processing:nuclei_segmentation:02} and~\ref{figure:image_processing:nuclei_segmentation:03}.

There are many technical definitions and implementations of the watershed algorithm, which can be applied for various segmentation problems. The watershed transform may be applied to the raw pixel intensity image, or a transformed version of the image. For separation of touching nuclei a watershed transform was performed on a transformed image. A euclidean distance transform was first applied, so that each foreground pixel is given a value, relative to the distance to its nearest boundary. A watershed on a euclidean distance transformed image, gives a watershed based entirely on the shape characteristics of the binary objects, where markers are the local maxima of the distance function to the background for separating overlapping objects.

The \emph{skimage.morphology.watershed} function was used to perform a watershed in this pipeline. It apportions pixels into marked basins, and returns a labelled image. A priority queue is used to hold the pixels with the metric for the priority queue being pixel value. A secondary metric for the priority queue is the time of entry into the queue, this settles any ties in favor of the closest marker~\cite{scikit-image}. The entry time onto the queue solves two problems: a pixel should be assigned to the neighbour with the largest gradient or, if there is no gradient, pixels on a plateau should be split between markers on opposite sides~\cite{Soille1990}.

\subsubsection{Support vector machine nuclei classification}
A supervised machine learning binary classification was used following application of, Otsu's thresholding, binary hole filling, and a watershed transform. The classifier predicts the class of segmented foreground objects to identify nuclei or non-nuclei foreground structures. Where non-nuclei segmented structures could be the result of staining artifacts, debris, dead cells or very small thresholded regions for example. Initial attempts at removing non-nuclei structures from the image were inadequate, by for example removing connected components less than a specified size. Although this size filter was effective for removing the majority of debris and small thresholded regions, it was not effective for removal of staining artifacts and dead cells.

Identifying nuclei from other structures can be approached as a binary classification problem. The objective of which is to separate foreground objects into two classes, nuclei and non-nuclei. A support vector machine (SVM) is commonly used for binary classification~\cite{Cortes1995}, and has been used here to generate a model for nuclei classification. Implementation of the classifier used the region properties measured morphological and pixel intensity features for each segmented object. Implementation of the classifier used the LIBSVM library~\cite{Chang2011}, a radial basis function kernel and practical advice from~\cite{Hsu2008}.

\paragraph{Labelled data set}
To apply SVM classification a set of labelled training data was required where each instance in the training data is assigned a class label. In the case of nuclei objects a label of 1 is given  and a 0 in the case of non-nuclei objects.

Generation of a labelled training set was semi-automated, to reduce tedious manual labour. A random selection of 300 nuclei stained images were taken from three separate experimental data sets, the images were segmented by Otsu's method, hole filling, and a watershed transform. The resulting binary output image was saved for each of the 300 images, and for each segmented object a set of 14 morphometric and pixel intensity features were extracted. This gave an intensity and morphometric results features data table consisting of 14510 objects, of unknown class.

The class of each objects in the results features data table was determined in a semi-automated fashion. In the binary images very small objects beneath the resolution limit of the microscope were removed as noise, the larger remaining structures were cross referenced with their raw nuclei stained images, and where a non-nuclei structure had been incorrectly segmented its pixels were set to background. In this way all incorrectly segmented foreground object were removed from the binary images. The binary images were then used as a reference set. For each of the 14510 instances in the results features data, the pixel value at the $x$ and $y$ centroid position for the structure was checked. The class was assigned by reading the pixel value corresponding to the location of the segmented object in the binary reference image set. If the pixel value was that of a foreground pixel then the object was a nuclei and assigned a label 1. If the pixel value was that of a background pixel then the object was a non-nuclei and was assigned a label of 0. Of the 14510 examples 9425 were labelled as nuclei and 5085 non-nuclei objects.

\paragraph{Data pre-processing}
For effective training of an SVM classifier some data pre-processing steps were performed. Firstly, from the labelled data set only numeric features containing morphometric and pixel intensity information were retained. The categorical attributes were removed, specifically row, column, field of view and particle ID numbers were removed (see Table~\ref{table:endothelial_morphometry:region_properties}).

The remaining features were scaled to standardise their range of values, thereby avoiding certain features with greater numeric ranges from dominating the function training. There are various methods of feature scaling, here a standardisation method was used. This calculates the mean ($\bar{x}$), and standard deviation ($\sigma$), for each feature, then for each sample subtracts the mean feature value and divides by the standard deviation feature value, as given by,
\begin{equation}
x'=\frac{x-\bar{x}}{\sigma}.
\end{equation}

\paragraph{Cross-validation and grid search}
The classification task here involves separating the data into training and testing sets. The data in the training set contains one predicted value and multiple features. The objective of SVM classification is to use the training data to produce a model, which can accurately predict the target values of the test data given only the test data features. Training vectors are mapped onto a higher dimensional space, and the linear separating hyperplane with the maximal margin in this higher dimensional space found. There are multiple kernel functions for solving this problem, the radial basis function is usually a good choice in problems that have many more instances than features~\cite{Hsu2008}.

The radial basis function kernel has two parameters the cost function, $C$, and gamma $\gamma$. These parameters should be optimised so that the classifier can accurately predict unknown data. A grid search was used for parameter optimisation, where a range of $C$ and $\gamma$ parameters are specified, and for every possible combination of these parameters a model trained and the predictive accuracy of the model evaluated. A coarse grid search was performed, with $C$ values in the range $10^{-2}$ to $10^{10}$ and $\gamma$ values in the range $10^{-9}$ to $10^{3}$, as shown in Figure~\ref{figure:cost_gamma_heatmap:base10}. Followed by a finer grid search, to identify a more precise $C$ and $\gamma$ value. The fine grid search used $C$ values in the range $2^{-5}$ to $2^{15}$ and $\gamma$ values in the range $2^{-15}$ to $2^{3}$, as shown in Figure~\ref{figure:cost_gamma_heatmap:base2}.
\begin{figure}[htbp]{}
	\centering
	\begin{subfigure}[b]{0.7\linewidth}
		\includegraphics[width=\linewidth]{cost_gamma_heatmap_base_10}
		\caption{}
		\label{figure:cost_gamma_heatmap:base10}
	\end{subfigure}
	\begin{subfigure}[b]{0.7\linewidth}
		\includegraphics[width=\linewidth]{cost_gamma_heatmap_base_2}
		\caption{}
		\label{figure:cost_gamma_heatmap:base2}
	\end{subfigure}
\caption[Radial basis function grid-search parameter optimisation]{Heatmaps depicting, on a gradient intensity scale the accuracy of support vector machine classification with models trained at various combinations of $C$ and $\gamma$ parameters. A 5-fold cross validation is used for each parameter combination so an accuracy and standard deviation of the parameter combination is returned. The plot in (a) is a coarse grid search over a base 10 logarithmic range, and in plot (b) the search was refined over a base 2 logarithmic range.}
\label{figure:cost_gamma_heatmap}
\end{figure}

The 14510 example labelled data points were shuffled and split into a training and validation group of 8706 examples and a test group of 5804 examples. A 5-fold cross validation was performed, for each $C$ and $\gamma$ value combination. In 5-fold cross-validation the training and validation group was randomly shuffled and split into 5 groups. Sequentially each subset was tested using the classifier trained on the remaining 4 subsets. The mean predictive accuracy accuracy and standard deviation across the 5 groups was then reported. In this way each example in the whole training set is predicted once so the cross-validation accuracy is the percentage of data which are correctly classified. Cross-validation is important to prevent overfitting of a model.

The most accurate model was found searching the finer base 2 $C$ and $\gamma$ parameter grid search. A $C$ value of 8.0 and $\gamma$ value of 0.03125, were found to be optimal parameter choices.
\paragraph{Implementation}
The SVM classifier model was tested in section~\ref{endothelial_morphometry:performance_evaluation:nucleus} and used to exclude non-nuclei objects on each image in a dataset. First an initial segmentation was performed via thresholding, binary hole fill and a watershed transform. Following an initial segmentation all segmented objects morphometric features were measured. This array of features was then pre-processed, by dropping non-numeric features, and scaling the feature values. An identical feature scaling was applied to scale the features as was applied in training. The SVM classifier was then used to predict the classification of all objects by their morphometric and pixel intensity features. Objects that were predicted to be non-nuclei were removed by their pixel value in a labelled image. For the remaining objects a binary image was created and relabelled, before morphometric features were re-measured. Measuring the morphometric features was necessary twice to generate the relevant output contours, although more computationally expensive.

\subsection{Cell segmentation}
\label{endothelial_morphometry:image_processing:cell}
The segmentation of individual endothelial cells is of particular importance in this study because it allows for a whole new layer of analysis on a cell by cell basis. Having performed a cell segmentation all other segmented organelles can be assigned to their respective cell. To do this each segmented organelle was assigned an identifier, relating to the cell from which it was derived. Stages in cell segmentation are outlined in Figure~\ref{figure:image_processing:flowchart}, and the major intermediary stages are shown visually in Figure~\ref{figure:image_processing:cell_segmentation}.

The general approach to cell segmentation involved pre-processing steps to enhance contrast and reduce noise (see Figure~\ref{figure:image_processing:cell_segmentation:clahe_denoise}), followed by separation of cells in the confluent monolayer. A range of techniques were trialled to separate touching cells in the confluent endothelial monolayer. Methods were trialled based on a survey of automated segmentations applied to optical imaging of mammalian cells~\cite{Bajcsy2015}. This survey of methods categorises segmentation methods as being spatially blind or spatially guided, where spatially blind techniques are essentially threshold based. As expected spatially blind methods such as thresholding were not reliable for finding cell boundaries. These methods were not adept at handling the intensity variation along cell boundaries, variation in staining and overlapping cells. Spatially blind techniques also do not use information provided by nuclei seed points.

Spatially guided techniques produced more accurate cell segmentation results, using nuclei as cell markers. Of the spatially guided segmentation methods region growing, evolving generalised voronoi diagram~\cite{Yu2010}, random walk, level set methods and marker-based watersheds were trialled. Region growing and level sets were found to be too computationally expensive for the scale of the high-throughput surveys, and the results were inconsistent with different staining protocols. The remaining three techniques, evolving generalised voronoi, random walk segmentation and marker based watershed produced comparable results. The watershed method was used because it is efficient and easily implementable in Python through scikit-image~\cite{VanderWalt2014}.

To perform the watershed the pre-processed image was inverted and the binary nuclei image added by performing an element-wise minimum with the binary nuclei image. A marker based watershed transform was used to find cell boundaries according to the nuclei markers. A cell was segmented for every nucleus, but if the cell was on the image border it has all its pixels set to background. Cells on the border region are assigned a pixel value of zero, since they are not complete cells, single cell analysis is not possible, see Figure~\ref{figure:image_processing:cell_segmentation:cell_labels}. These cells are excluded from single cell analysis, however can still be used for population level analysis.

\begin{figure}[htbp]\centering
	\begin{subfigure}[b]{0.45\linewidth} %001001004.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{cell_00_original}
		\caption{}
		\label{figure:image_processing:cell_segmentation:original}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth} %001001004.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{cell_02_clahe_denoise}
		\caption{}
		\label{figure:image_processing:cell_segmentation:clahe_denoise}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth} %001001004.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{cell_03_invertAddNuclei}
		\caption{}
		\label{figure:image_processing:cell_segmentation:invertAddNuclei}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth} %001001004.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{cell_04_watershed}
		\caption{}
		\label{figure:image_processing:cell_segmentation:watershed}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth} %001001004.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{cell_labels}
		\caption{}
		\label{figure:image_processing:cell_segmentation:cell_labels}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth} %001001004.tif from 160413_Jess_SPA_Morph
		\centering
		\includegraphics[width=\linewidth]{cell_contours}
		\caption{}
		\label{figure:image_processing:cell_segmentation:contours}
		\vspace{1ex}
	\end{subfigure}
	\vspace{-1ex}
\caption[Cell segmentation]{Processes involved in segmentation of cells. Image (a) is the raw image, (b) after applying contrast limited adaptive histogram equalisation and denoising, (c) following inversion and addition of nuclei, (d) depicts the watershed transform, and (e) is after clearing borders and relabelling, finally image (f) is a quality control image with segmentation contours.}
\label{figure:image_processing:cell_segmentation}
\end{figure}

Endothelial cells in microtitre plate wells form a confluent flat monolayer, where cell size, shape and orientation vary. Cells were demarcated with a plasma membrane staine, as can be seen in Figure~\ref{figure:image_acquisition:plasma_membrane}. The plasma membrane stain was used to segment the cell boundaries, in conjunction with seed points from cell nuclei. Since nuclei are used as markers for cells the accuracy of nuclei segmentation is of fundamentally importance, for ensuring accuracy of cell segmentation.

The segmentation method presented here assumes that each segmented nucleus is contained within exactly one cell, in other words, each cell can only contain one nucleus. This is almost always the case, although binucleation can occur and cells undergoing mitosis can be imaged at any stage in division. The proportion of cells undergoing mitosis and the number of binucleated cells, is variable depending on the experimental protocol.

\subsubsection{Adaptive histogram equalisation}
An initial preprocessing step was to perform contrast enhancement, using a contrast limited adaptive histogram equalisation (CLAHE)~\cite{Ketcham1974}. Histogram equalisation improves the contrast in an image globally, by effectively spreading out the most frequently used intensity values. The adaptive method of histogram equalisation, performs histogram equalisation on local regions of the image. It is therefore suitable for improving the local contrast and enhancing the edge definition in each region of an image.

The adaptive method of histogram equalisation has a drawback that in homogeneous image regions with only small intensity variation it has a tendency to over-amplify noise. By limiting the contrast enhancement in adaptive histogram equalisation this over-amplification can be avoided. The contrast amplification is calculated for a pixel from the slope of the transformation function, which is proportional to the slope of the neighbourhood cumulative distribution function. CLAHE limits the amplification by clipping the histogram at a predefined value before computing the cumulative distribution function. This limits the slope of the cumulative distribution function and therefore of the transformation function.

CLAHE was used in this instance to improve contrast and enhance junctions between cells. The CLAHE technique works well in images where out of focus regions maybe lighter or darker than the rest of the image. The kernel size and clipping limit parameters were chosen based on experimentation over multiple images from both available staining techniques.

\subsubsection{Noise reduction}
The plasma membrane stained image contains poisson noise from the imaging sensor, as well as noise from small punctae within the cell. Steps were taken to reduce noise in these images by performing a noise reduction step. For this purpose a bilateral denoising filter and total variation filter were investigated, these algorithms were chosen because they produce posterised images with flat domains whilst maintaining edges. This is appropriate for cell segmentation where their are large homogeneous regions within cells and well defined edges.

A bilateral filter is an edge-preserving and noise reducing filter. It averages pixels based on their spatial closeness and radiometric similarity. On the other hand the principle of total variation denoising is to minimise the total variation of the image, which can be roughly described as the integral of the norm of the image gradient. 

Total variation denoising with Chambolle's algorithm~\cite{Chambolle2004} was found to be more effective for noise reduction in plasma membrane stained images, a weight parameter was chosen based on experimentation over multiple images from several datasets. The outcome of applying CLAHE and a total variation denoising can be seen in Figure~\ref{figure:image_processing:cell_segmentation:clahe_denoise}.

\subsubsection{Watershed transform and clear borders}
Segmentation of cells by the watershed transform was found to give a computationally efficient and reliable output. The watershed transform used nuclei as seed points, to do this the denoised image is inverted and binary nuclei markers added, as is displayed in Figure~\ref{figure:image_processing:cell_segmentation:invertAddNuclei}. The nuclei markers form the seed points for the watershed transform, which is performed and the result visible in Figure~\ref{figure:image_processing:cell_segmentation:watershed}. The scikit-image watershed function returns a labelled image (Figure~\ref{figure:image_processing:cell_segmentation:watershed}. Connected components on the image border are removed, and the cell relabelled, so background pixels are 0 and then cells are assigned consecutive higher pixel value, as shown in Figure~\ref{figure:image_processing:cell_segmentation:cell_labels}.

\subsection{Weibel-Palade body segmentation}
\label{endothelial_morphometry:image_processing:wpb}
Segmentation of WPBs was achieved with a method similar to that described in the literature and used previously in our research group~\cite{Ferraro2014, Stevenson2014}. The exact method of segmentation has been adapted to the varying demands of different staining protocols and antibody combinations. In earlier trials, non-specific staining of the endoplasmic reticulum was causing uneven background illumination in the acquired images. A rolling ball background subtraction~\cite{Sternberg1983} pre-processing step improved the signal to noise ratio in these images. As both the staining and imaging protocols have improved the fidelity of the images has increased and this pre-processing step is unnecessary.

Within an image both strongly fluorescent and weakly fluorescent WPBs are present, the segmentation method needed to accurately find contours of both, as is seen in Figure~\ref{figure:wpb_segmentation-zoom}. Additionally, closely apposed WPBs needed to be identified as separate objects. A global thresholding approach is unable to meet these criteria, so a local adaptive thresholding was applied. In this case the threshold value is the weighted mean for the local neighborhood of a pixel subtracted by a constant~\cite{scikit-image}. An experimentally determined subtraction constant and local neighbourhood or block size was used, and the segmentation verified by a biologist.

\begin{figure}[htbp!] %004004002.tif from 160413_Jess_SPA_Morph
	\centering
	\begin{tikzpicture}[figurename=figure:wpb_segmentation,
		zoomboxarray,
		zoomboxes right,
		zoomboxarray columns=2,
		zoomboxarray rows=2]
		\node [image node] {\includegraphics[width=0.49\textwidth]{wpb_00}};
		\zoombox[magnification=5,color code=red]{0.560, 0.750}
		\zoombox[magnification=5,color code=yellow]{0.737, 0.450}
		\zoombox[magnification=5,color code=green]{0.135, 0.171}
		\zoombox[magnification=5,color code=blue]{0.337, 0.590}
	\end{tikzpicture}
\caption[Segmentation contours of Weibel-Palade bodies]{Fluorescent Weibel-Palade bodies are shown in image (a) with overlaid segmentation contours by adaptive thresholding. Image (b) shows magnified regions of the image, in the red, yellow and green boxes the segmentation of both highly and weakly fluorescent organelles can be seen. The blue box shows the removal of a cluster of WPB that were inseparable and therefore removed from analysis.}
\end{figure}

Before extracting morphological features, segmented objects beneath the resolution limit of the optical system were removed. Large areas, where multiple WPBs were clumped closely together were also removed. These clusters were unfortunately inseparable, at the resolution of the optical system.

\subsection{Exocytic sites segmentation}
\label{endothelial_morphometry:image_processing:exit_sites}
The WPB cargo VWF is amenable to antibody labelling when exocytosed. Exocytosed VWF is arrested at the cell surface adjacent to the exocytic sites, and appears as round blobs, see Figure~\ref{figure:exit_sites_segmentation-image}.

\begin{figure}[htbp!] %001004004.tif from 151002_Jess_PMAdilutions
	\centering
	\begin{tikzpicture}[figurename=figure:exit_sites_segmentation,
		zoomboxarray,
		zoomboxes right,
		zoomboxarray columns=2,
		zoomboxarray rows=2]
		\node [image node] {\includegraphics[width=0.49\textwidth]{exit_sites_00}};
		\zoombox[magnification=5,color code=red]{0.400, 0.820}
		\zoombox[magnification=5,color code=yellow]{0.090, 0.510}
		\zoombox[magnification=5,color code=green]{0.625, 0.245}
		\zoombox[magnification=5,color code=blue]{0.835, 0.175}
	\end{tikzpicture}
\caption[Segmentation contours of exocytic site]{Segmentation contours of a von-Willebrand's factor stained exocytic sites image is seen in image (a). Image (b) shows magnified regions of the image, where the red and yellow boxes, show a cluster of exit sites, and a single exit site respectively. The green and blue boxed images demonstrates the watershed transform.}
\end{figure}

These exocytic sites were identified using a thresholding technique. Firstly, image noise was reduced using a Gaussian blurring pre-processing step. A sigma value was chosen for the Gaussian blur that does not impact the image resolution. A Moment-preserving threshold~\cite{Tsai1985} was calculated over all unstimulated images in a data set, this calculated value was used to obtain a binary mask image.

Adjacent exit sites segmented as a single object were split using a marker-based watershed flooding algorithm. Finally, segmented objects beneath the resolution limit of the optical system were removed, this was calculated by Abbe's equation to be 5 pixels. Morphometric and intensity measurements could then be extracted.

\subsection{Cell assignment}
\label{endothelial_morphometry:image_processing:cell_assignment}
Analysis of morphometry of endothelial organelles is a valuable outcome from high-throughput microscopic studies of endothelial cells. Further value is added by assessing cellular characteristics by assignment of organelles to their relevant cell. The assignment of organelles is performed automatically on plates where a plasma membrane channel is present. The assignment of organelles to their relevant cell was achieved with a function, as in listing~\ref{listing:cell_assignment}.

\begin{lstlisting}[
	style=python,
	label={listing:cell_assignment},
	caption={Python function to determine in which cell a segmented organelle is located}
	]
def assignCell(label_image, intensity_image, features):
    properties = measure.regionprops(label_image, intensity_image)
    cell = pd.Series([prop.max_intensity for prop in properties])
    features['cell'] = cell
    cols = features.columns.tolist()
    cols.insert(4, cols.pop())
    features = features[cols]
    features[0] = features[0].map(str) + features['cell'].map("{:03}".format).map(str)
    return features
\end{lstlisting}

The \emph{assignCell} function takes three inputs, a label image, in which segmented organelles are assigned a unique pixel value or label, an intensity image, which is the \emph{cell\_labels} image (shown in Figure~\ref{figure:image_processing:cell_segmentation:cell_labels}), and lastly a features table. The features table contains the morphological measurements for each segmented organelle in the label image. In lines 2 and 3 of listing~\ref{listing:cell_assignment} the scikit-image \emph{regionprops} function takes the coordinates of each segmented and labelled organelle, then measures in the \emph{cell\_labels} intensity image the maximum pixel intensity of those coordinates. A Pandas~\cite{McKinney2011} series is returned with the pixel intensity for each segmented organelle in the labelled cell image. Cells on the image edge return a pixel value of zero, so can be included or excluded in further analysis.

Lines 4 to 7 of listing~\ref{listing:cell_assignment} inserts the found pixel values as a new column into the morphological features table. Each cell in the dataset is given a unique identifier in line 8, which adds the cell number to the particle\_id. In data where a plasma membrane stain is present and cell segmentation is performed a particle\_id is returned constructed of the row number, column number, field of view number and cell number. Grouping data by these particle\_id strings allows for analysis on a cell by cell basis. Finally, line 9 of the function returns the features table, which can then be appended to file. 

\subsection{Synthetic coordinates}
\label{endothelial_morphometry:image_processing:synthetic_coordinates}
The coordinate data of segmented organelles can be used to study their spatial distributions, and how different secretagogues and drug treatments may effect the spatial distribution. This is of particular interest when looking at VWF exocytic sites and WPBs.

There are many ways in which coordinate data can be utilised to investigate spatial distributions. A useful approach was in testing for complete spatial randomness (CSR), this is a process whereby point events occur within an area in a random fashion. Several approaches were trialled to investigate whether organelles were distributed in a random fashion within cells. The quadrant method is a simple approach that subdivides each cell into congruent rectangular sub-cells and the number of points within each cell counted and the distribution analysed. This method has several major drawbacks; it requires quadrants to have equal area, where the partition size impacts the results and there is no obvious method to chose the quadrant size.

A better approach calculates the euclidean distances between points and their nearest neighbors, requiring no artificial partitioning scheme. The Clark-Evans test~\cite{Clark1954} was then tried as a means to test CSR. In each cell the density of points was calculated and assuming a Poisson distribution used to determine a mean nearest neighbour distance for the cell. For each cell the ratio of the predicted nearest neighbour distance to the real mean nearest neighbour distance was calculated. Values $\sim$ 0 indicate clustered points, $\sim$ 2 are regular ordered points and values $\sim$ 1 are randomly distributed. The Clark-Evans test was however not reliable, since it assumes that cells are infinite or very large. The effects at the region boundary for cells was significant and there was no easy method to compensate for edge effects as with regular shapes.

Finally, an approach for testing the degree of spatial randomness was arrived at using synthetic coordinates. These synthetic coordinates generated artificially could then be used to compare to the real data points. The generation of synthetic coordinates was performed using the Python function shown in listing~\ref{listing:synthetic_coordinates}, this takes as input the cell labels image, an organelle features table and a number. The number is preset by the user, to determine how many coordinate pairs to generate, 100 or 1000 pairs are typically used.

\begin{lstlisting}[
	style=python,
	label={listing:synthetic_coordinates},
	caption={Python function to generate a set of synthetic coordinates for each organelle}
	]
def syntheticCoordinates(cell_labels, features, number):
    properties = measure.regionprops(cell_labels)
    coordinates =[prop.coords for prop in properties] 
    coords = np.empty([features.shape[0], 2]); coords.fill(np.nan)
    synthetic_coordinates = np.zeros([features.shape[0], 2*number])
    for i in range(number):
        for index, row in features.iterrows():
            cell_number = int(features['cell'][index])
            if (cell_number > 0):
                random_coordinates = coordinates[cell_number-1][np.random.randint(0,coordinates[cell_number-1].shape[0],1)]
                coords[index,0] = random_coordinates[0,1]
                coords[index,1] = random_coordinates[0,0]
        synthetic_coordinates[:,i*2] = coords[:,0]*pixel_dimension
        synthetic_coordinates[:,i*2+1] = coords[:,1]*pixel_dimension
    return synthetic_coordinates
\end{lstlisting}

All the coordinates in each cell of the labelled image are retrieved in lines 2 and 3 of listing~\ref{listing:synthetic_coordinates}. Two empty arrays are created in lines 4 and 5 to output the coordinate sets into. A nested for loop for the number of features and number of coordinate pairs to generate then generates random coordinates. Each row in the features table represents a segmented organelle, the cell number is retrieved for that organelle and if it is greater than 0, it is a non-edge cell so a synthetic coordinate is generated. This is done by sampling a random coordinate pair from the list of cell coordinates obtained in line 3. The \emph{syntheticCoodinates} function returns a data table with many synthetic coordinate pairs for each real coordinate pair.

\section{Performance evaluation}
\label{endothelial_morphometry:performance_evaluation}
The evaluation of image segmentation is a necessary and often overlooked stage in image analysis. Despite there being many algorithms and significant literature about image segmentation techniques, there is no universal agreement on evaluation of image segmentation algorithms~\cite{Benes2015}. For any given segmentation problem their are multiple possible segmentation algorithms that could be used, finding the optimal method and parameter choice requires evaluation metrics.

A cursory subjective evaluation of segmentation contours is usually a helpful starting point to assess a segmentation algorithm, however more thorough quantitative assessment is required to detect subtle differences between segmentation methods. In image processing and computer vision a comparison to a gold standard or reference segmentation data set is fundamental to performance evaluation.

The term gold standard refers to a benchmark that is available under reasonable conditions. It is not an objectively perfect set, but merely the best available~\cite{Cardoso2014}. In this case a gold standard is acquired from the most accurate segmentation procedure, generated by manually hand-labelling or semi-automatic labelling images. A ground truth reference set, is a set of measures that is known to be more accurate than the measurements of the system being tested. This could for example be obtained from higher resolution and higher magnification microscopy.

Image segmentation is often an ill defined problem, meaning there may not be a single gold standard segmentation. It is therefore useful to compare against multiple perceptually consistent interpretations of an image. These might be for example hand segmented by several experts in the field, hand segmentation of a gold standard is however a labour intensive process and this is often not feasible~\cite{Unnikrishnan2005}. The evaluation of a segmentation algorithms performance and generation of a gold standard data is also complicated by inconsistent data, since images of microscope samples vary in quality and character.

To evaluate the segmentation performance of nuclei, cell boundaries, VWF exocytic sites and WPBs in endothelial cells, methods and metrics have been chosen based on the type of image data and how the data was used. Performance evaluation of segmentation maybe concerned with the ability of the method to determine whether or not a particle exists as a binary problem, or for dividing spatial regions the ratio of overlap to the gold standard data is of more importance.

A secondary validation of segmentation methods is also established by the consistency of biological results achieved. For example whether the data is consistent with other methods of experimental methods such as low-throughput microscopy or enzyme-linked immunosorbent assays (ELISA).

\subsection{Nucleus segmentation}
\label{endothelial_morphometry:performance_evaluation:nucleus}
The segmentation of nuclei is crucial to accurate cell segmentation, where each nuclei is used as a seed point defining a cell. The presence or absence of a nuclei is therefore more important than the precise contours of the segmented object. The performance evaluation of nuclei is therefore treated as a binary classification problem. By visual inspection of segmented nuclei images it is clear that the contours are generally accurate to the nuclei edge.

A basic thresholding approach to nuclei segmentation achieves a reasonable degree of accuracy, which is suitable for the majority of nuclei. However, the segmentation is not suitable for segmentation of cells undergoing division, removing debris or other fluorescent non-nuclei objects, segmentation of cells on the image edge, and segmentation of dead cells. The frequency of these occurrences depends on the condition of the cells undergoing analysis, although generally the segmentation faults are a small proportion of the total number of nuclei objects. The SVM classifier and watershed transform were used to reduce the number of such errors, as described in section~\ref{endothelial_morphometry:image_processing:nuclei}.

A testing set of 5804 labelled gold standard segmented nuclei were used to asses the performance in a binary sense of nuclei classification. Optimal $C$ and $\gamma$ values were used to perform SVM classification on the 5804 example test set and the predictive ability evaluated. The predictive ability was evaluated by establishing the number of true positives, false positives, true negatives, and false negatives between the gold standard labelled data and the automated analysis, as is shown in Table~\ref{table:endothelial_morphometry:confusion_matrix}.

\begin{table}[htbp]
\caption{Confusion matrix of support vector machine classifier predictive ability applied to 5804 sample testing set, when using a radial basis function kernel and $C$ value of 8.0 with a $\gamma$ value of 0.03125. }
\label{table:endothelial_morphometry:confusion_matrix}
\centering
\begin{tabular}{cc|cc}
	\multicolumn{2}{c}{}&\multicolumn{2}{c}{True}\\
	\multicolumn{2}{c|}{}& p & n\\
	\cline{2-4}
	\multirow{2}{*}{Predicted}& p' & 1996 & 22\\ & n' & 145 & 3641\\
\end{tabular}
\end{table}

In this case a true positive, is a nuclei that is correctly predicted by the SVM model to be a nuclei, conversely a true negative is a non-nuclei object that has been correctly classified as a non-nuclei object. False positives are non-nuclei objects falsely identified as nuclei. Finally false negatives are nuclei falsely classified as non-nuclei objects. From these numbers the main classification metrics are shown in Table~\ref{table:endothelial_morphometry:performance_metrics}.

\begin{table}[htbp]
\caption{Performance metrics of classifier with optimal $C$ and $\gamma$ values.}
\centering
\label{table:endothelial_morphometry:performance_metrics}
\begin{tabular}{cccc}
	\toprule
	& Precision  & Recall & F1-score\\
	\midrule
	Non-nuclei   & 0.93       & 0.99   & 0.96    \\
	Nuclei       & 0.99       & 0.96   & 0.98    \\
	\bottomrule
	\toprule
	Average      & 0.97       & 0.97     & 0.97    \\
	\bottomrule
\end{tabular}
\end{table}

\subsection{Cell segmentation}
\label{endothelial_morphometry:performance_evaluation:cell}
Evaluation of the performance of cell segmentation considers the ratio of overlap between cell contours in a hand labelled gold standard compared to an automated segmentation method. Accurate cell segmentation impacts the assignment of organelles to their respective cell, and therefore essential to ensure valid conclusions when performing data analysis at a single cell level. For cell by cell analysis inaccuracy in defining cell contours is amplified by errors in detecting nuclei, as described in section~\ref{endothelial_morphometry:performance_evaluation:nucleus}.

To evaluate the similarity between gold standard cell segmentation and automatically segmented cell boundaries overlap ratio coefficients were used, namely the Dice coefficient~\cite{Dice1945}, and Jaccard index~\cite{Jaccard1912}. The Jaccard index measures similarity between two finite data sets, and it is defined as the size of the intersection divided by the size of the union of the two sets,
\begin{equation}
J(A,B) = \frac{|A\cup B|}{|A \cap B|} ,
\end{equation}
where $A$ and $B$ are two sets. Likewise, the Dice coefficient for two sample sets is given by,
\begin{equation}
D(A,B) = 2 \frac{|A\cap B|}{|A| + |B|}.
\end{equation} 
These metrics give a measure of the similarity and diversity of two sample sets, where in this case the sets are sets of pixels.

The Dice and Jaccard metrics were calculated for each cell by generating a pixel set for gold standard hand labelled cells, as shown in Figure~\ref{figure:performance_evaluation:gold_standard}, and automated segmentation contours as shown in Figure~\ref{figure:performance_evaluation:cell_automated}. The union and intersection of these two sets could then be used in the calculation of the Dice and Jaccard metrics, the union and intersection are in Figure~\ref{figure:performance_evaluation:cell_intersectionUnionCell}.

\begin{figure}[htbp]\centering
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{cell_goldStandard}
		\caption{}
		\label{figure:performance_evaluation:cell_gold_standard}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{cell_automated}
		\caption{}
		\label{figure:performance_evaluation:cell_automated}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{cell_intersectionUnionCell}
		\caption{}
		\label{figure:performance_evaluation:cell_intersectionUnionCell}
		\vspace{1ex}
	\end{subfigure}
\caption[Example cell pixel sets gold standard, automated segmentation, and union and intersection]{An example cell manually segmented to give a gold standard in (a), and the corresponding contours for the cell generated by an automated segmentation method in (b). Image (c) shows the union and intersection of the cell, where the intersection are the white foreground pixels and the union are the grey pixels in the background.}
\label{figure:performance_evaluation:cell}
\end{figure}

Optimal cell segmentation was found by calculating the Dice and Jaccard metrics, on a sample of 517 cells, where two different antibodies were used for staining, and a variety of automated segmentation methods applied. For this purpose cell boundaries were annotated on a sample set of 517 cells, where two staining methods were used, as shown in Figure~\ref{figure:performance_evaluation:antibody}.

\begin{figure}[htbp]\centering
	\begin{subfigure}[b]{0.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{cell_wga}
		\caption{}
		\label{figure:performance_evaluation:antibody_1}
		\vspace{1ex}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{cell_cadherin}
		\caption{}
		\label{figure:performance_evaluation:antibody_2}
		\vspace{1ex}
	\end{subfigure}
\caption[Excluded images]{Images that are unusable and have been excluded from further processing, by a manual inspection of images with high and low mean pixel values. Image (a) is occluded by debris or dirt and image (b), is symptomatic a laser malfunction on the microscope.}
\label{figure:performance_evaluation:antibody}
\end{figure}

An initial method to estimate cell boundaries was to apply a Voronoi decomposition of nuclei seed points. This method does not require staining of the plasma membrane. Instead the Voronoi tessellates an image using the nuclei centroids as seed points, cells are constructed from equidistant lines between nuclei. In datasets where plasma membrane staining was not available the Voronoi methods provides an estimation of cell boundaries.

Usually cell plasma membranes were stained and imaged, so a more precise segmentation method could be used. The mean Dice coefficient and Jaccard index for different segmentation approaches are displayed in Table~\ref{table:endothelial_morphometry:dice_jaccard}. A host of preprocessing and segmentation methods were trialled for cell segmentation, as discussed in section~\ref{endothelial_morphometry:image_processing:nuclei}. Many of these methods were found to be inappropriate even with a cursory look at the resulting segmentation contours. The two most promising methods identified were the evolving generalised voronoi diagram (EGVD)~\cite{Yu2010} and a marker based watershed~\cite{Roerdink2000}. 

An automated method written in Python for each nucleus within the 517 cell data set found the associated hand labelled and automated segmentation contours and calculated the Dice coefficient and Jaccard index. The Voronoi and watershed methods were performed natively in Python, whilst segmentation contours for the EGVD method  were generated in the StemCell3D software~\footnote{W. Yu, H. Srivats, S. Shvetha, S. C. Chia, V. Pascal, A. Sohail andH.K. Lee, StemCell3D software, \url{http://imaging.imb.a-star.edu.sg/17/stemcell3d.html}, accessed 2015-11-28}.

\begin{table}
\caption{The mean Dice coefficient and Jaccard index similarity metrics over 517 cells for antibody I (wheat germ agglutinin) and antibody II (VE-cadherin), and multiple segmentation methods applied.}
\centering
\label{table:endothelial_morphometry:dice_jaccard}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{Segmentation method} & \multicolumn{2}{c}{Antibody I} & \multicolumn{2}{c}{Antibody II} \\ 
\cmidrule{2-5}
	& Dice & Jaccard & Dice & Jaccard \\
\midrule
	voronoi & 0.68 $\pm$ 0.19 & 0.54 $\pm$ 0.19 & 0.68 $\pm$ 0.19 & 0.54 $\pm$ 0.19\\
	watershed & 0.42 $\pm$ 0.17 & 0.28 $\pm$ 0.13 & 0.47 $\pm$ 0.17 & 0.32 $\pm$ 0.14\\
	CLAHE$+$watershed & 0.78 $\pm$ 0.22 & 0.69 $\pm$ 0.25 & 0.75 $\pm$ 0.25 & 0.65 $\pm$ 0.26\\
	CLAHE$+$denoise$+$watershed & 0.78 $\pm$ 0.22 & 0.69 $\pm$ 0.24  & 0.78 $\pm$ 0.22 & 0.68 $\pm$ 0.24\\
	EGVD & 0.79 $\pm$ 0.19 & 0.68 $\pm$ 0.21 & 0.76 $\pm$ 0.18 & 0.65 $\pm$ 0.20\\
\bottomrule
\end{tabular}
\end{table}

The best performing method of cell segmentation uses a contrast limited adaptive histogram equalisation (CLAHE), followed by a denoising step and finally a watershed transform. The performance was comparable across antibody I and antibody II.

Whilst the plasma membrane stained method performed better on average than the Voronoi decomposition, there is a higher variability in the success of the plasma membrane stained method. Within the sample of 100 randomly selected cells, in 24 cases the Voronoi segmentation gave a more accurate segmentation result according to both the Dice and Jaccard index than the plasma membrane stained method. When the plasma membrane staining method fails it is more pronounced than the Voronoi, the Voronoi decomposition divides the space into regions depending on the seed points. The cell size is more uniform than the plasma membrane method, in certain staining conditions the plasma membrane staining method failed to identify plasma membrane boundaries, the Voronoi gave an averaged result of cellular boundaries that is more accurate. Where the plasma membrane staining is of a good intensity and cell boundaries are well defined the plasma membrane staining method is effective. In certain cases however the staining is ambiguous and it is not clear where are cell boundaries. Unclear cell boundaries maybe the result of overlapping cells or plasma membrane in the same z-axis alignment as the nucleus.

\subsection{Weibel-Palade body segmentation}
\label{endothelial_morphometry:performance_evaluation:WPB}

\subsection{Exit sites segmentation}
\label{endothelial_morphometry:performance_evaluation:exit_sites}

\subsection{Mislabelling error}
\label{endothelial_morphometry:performance_evaluation:cell}
