\chapter{Automated detection and tracking of leukocytes \emph{in vitro}}
\label{leukocytes}
\ifpdf
    \graphicspath{{chapter_4/figs/}}
\fi

\nomenclature[z-THP1]{$THP-1$}{A human monocytic cell line derived from an acute monocytic leukemia patient}
\nomenclature[z-CLAHE]{$CLAHE$}{contrast limited adaptive histogram equalisation}
\nomenclature[z-OpenCV]{$OpenCV$}{open source computer vision library}
\nomenclature[z-MOTP]{$MOTP$}{multiple object tracking precision}
\nomenclature[z-MOTA]{$MOTA$}{multiple object tracking accuracy}

Interaction between the endothelial monolayer and leukocytes were recorded with a phase contrast microscope and high frame rate microscope camera. Manual quantification of interaction events in the acquired video sequence is very time consuming, potentially inaccurate and laborious. This chapter describes a quantitative computational method for leukocyte cell detection and tracking using a Haar-like features object detection framework. The method is capable of automatically identifying and accurately tracking multiple leukocyte trajectories \emph{in vitro} adhesion assays.

Image data for use in this chapter was acquired by: Jess McCormack and Francesca Patella.

\section{Introduction}
\label{leukocytes:introduction}
Mechanisms of leukocyte recruitment can be studied in leukocyte endothelium flow adhesion assays \emph{in vitro}, in the presence of physiological levels of shear stress. Recruitment of leukocytes requires leukocyte interaction with vascular endothelium and consists of multiple steps in a consecutive adhesion cascade. The mechanisms of adhesion can be inferred from analysis of leukocyte endothelial interaction in flow assays, where the endothelial monolayer is in differing activation states.

To observe mechanisms of leukocyte recruitment across human endothelial cells an \emph{in vitro} fluid flow chamber was used. A microscope capable of phase contrast microscopy connected to a flow assay system recorded video frames of leukocytes in culture medium, flowing through the chamber, over a confluent monolayer of HUVECs. Physiological levels of shear stress were maintained by controlling the flow rate. Hypotheses could then be tested by comparing the effect of endothelial cell conditions that inhibit or promote leukocyte recruitment as compared to a control group.

Phase contrast microscopy is advantageous for the study of live cells and their motility. It provides sufficient contrast for cell edge detection without exogenous dyes, using only moderate levels of light. Resulting images are free from staining artifacts and photo-damage, as are common in fluorescence microscopy~\cite{Ambuhl2012}. Phase contrast microscopy translates tiny variations in the phase of incident light from a specimen into perceptible changes in light amplitude. Phase differences in light occur due to the relative refraction index of the medium through which the light has travelled (see \autoref{introduction:microscopy:phase_contrast_microscopy}).

\subsection{Shear stress}
\label{leukocytes:introduction:shear}
The shear stress under which these \emph{in vitro} experiments are carried out is set to approximate the conditions under which these vein endothelial cells would operate. The rate of shear is proportional to the flow rate in these experiments, and the system maintains a suitable flow rate to generate an appropriate shear stress. Calculation of the shear stress is important in the interpretation of the acquired experimental data.

Shear stress is a force along a plane parallel to the imposed stress causing deformation by slippage of a material. Endothelial cells are subjected to shear stress from blood flow and a mechanical shear stress is converted into intracellular signals that affect cellular functions. In a flow assay a physiologically relevant shear stress is maintained over the endothelial monolayer in the $\mu$-slide chamber by controlling the flow rate ($\Phi$) in the system. To calculate the resulting shear stress on the cells, the mathematical model assumes a Newtonian fluid in laminar flow between infinitely wide parallel plates, the wall shear stress $\tau$ is calculated as:
\begin{equation}
	\tau=\frac{6\eta}{h^2b}\Phi,
\end{equation}
where, ($\eta$) the dynamical viscosity, ($h$) the height of the channel and ($b$) the channel width~\cite{Bacabac2005}. A viscosity value of \SI{1E-3}{Pa} appropriate for water at \SI{22}{\degreeCelsius} is here approximated for the viscosity of the cell culture medium containing leukocytes, and a shear stress of \SI{0.07}{\pascal} maintained.

\subsection{Quantitative analysis}
\label{leukocytes:introduction:quantitative}
Quantitative analysis of leukocyte flow assays aim to evaluate the degree of interaction of THP-1 cells with the endothelium. Experiments \emph{in vivo} often use a measure called the \emph{rolling flux}, which is the number of leukocytes crossing an imaginary line across the observed vessel~\cite{Sperandio2006}. A traditional approach to quantification \emph{in vitro} involves counting the number of interactions occurring between the leukocytes and endothelium, where an interaction would be deemed an event in which a leukocyte slows significantly or stops. This method of analysis is time consuming, requires a subjective judgement and is prone to observer bias. It is proposed that a computational approach to quantify these rolling assays, would yield much more quantitative data about interaction events, leading to biological insight into the adhesion cascade and mechanisms of leukocyte rolling.

Existing computational approaches to tracking of leukocytes have mainly been focused on the \emph{in vivo} modality. There is the additional challenge \emph{in vivo} of removing the respiratory motion during the video~\cite{Ray2002,Sperandio2006}. Techniques exist for quasi-automated tracking of leukocytes~\cite{Acton2002, Debeir2005} \emph{in vitro}, where leukocytes are identified manually by the operator.

For our experimental setup a solution involving operator identification is impractical due to the quantity of leukocytes to be identified over the duration of the video. A method has therefore been developed for leukocyte detection and tracking without operator identification and minimal parameter adjustments between experiments.

\subsection{Leukocyte interaction velocity}
\label{leukocytes:introduction:velocity}
Fluid flow through a tube or pipe can generally be laminar or turbulent, where the flow profile is largely dependant on the flow rate and viscosity of fluid. Turbulent flow is a chaotic flow regime characterised by the presence of vortices or eddies. Generally, turbulent flow occurs at higher flow rates and is difficult to model. On the other hand, laminar flow in a pipe has a predictable parabolic distribution of velocities across a cylindrical cross-section. In laminar flow the velocity of parallel fluid layers have a constant velocity relative to neighbouring layers. This is manifest for a parallel-plate as a profile increasing from stationary at the walls towards a maximum at the cross-sectional centre. Laminar flow is assumed within the parallel-plate flow chamber used in the leukocyte interaction assay, given the leukocyte medium viscosity and flow rate of the system.

Distinguishing leukocytes retarded by interaction with the endothelial monolayer is complicated by the differential velocity profile in laminar flow. The velocity of a leukocyte is dependent not only on its position in the flow profile but also molecular interactions occurring with the endothelial monolayer. In the experimental setup used with the microscope acquiring from an above view, it is not possible to determine the height of the leukocyte in the flow profile. There is insufficient information to distinguish free flowing and interacting leukocytes at all heights in the flow profile. 

A minimum velocity or critical velocity of non-interacting leukocytes can be calculated, on the assumption that most interaction occurs for leukocytes flowing close to the vessel wall. The leukocytes in faster flow-streams if interacting will be retarded and pulled towards the vessel wall. In the outer flow-streams a critical velocity has been calculated to distinguish interacting leukocytes from free-flowing leukocytes.

Calculation of the leukocyte critical velocity requires in the first place an approximation of the mean flow velocity ($\bar{v}$), of the leukocyte medium in the parallel-plate chamber,
\begin{equation}
	\bar{v}=\frac{v_{max}}{2-\epsilon},
\end{equation}
this is based on some known parameters and the ratio $\epsilon = D_L/D_C$. Where ($D_L$) is the leukocyte diameter and ($D_C$) the chamber diameter. The chamber diameter is given as \SI{0.4}{\milli\meter} and a value of \SI{15}{\micro\meter} is used as the average diameter of a leukocyte~\cite{Dorgan1998}. The value ($v_{max}$) is the maximum leukocyte velocity or the velocity of leukocytes in the centre fastest laminar stream. 

A value of ($v_{max}$) was approximated by measurement of the distance travelled during the camera exposure of the fastest leukocytes in a video. This can be seen in a video frame by the length of the leukocyte trail, this is the distance travelled by a leukocyte during the camera exposure time. From the distance travelled and the camera exposure time of \SI{30}{\milli\second} a maximum velocity can be calculated.

The critical velocity ($v_{crit}$) can then be estimated as,
\begin{equation}
	v_{crit}=\bar{v}\cdot\epsilon\cdot(2-\epsilon),
\label{equation:critical_velocity}
\end{equation}
using the mean flow velocity ($\bar{v}$) and the ratio ($\epsilon$) in this experimentally derived equation~\cite{Ley1991}. Any cell with a velocity below the critical velocity is likely to be retarded by an adhesion interaction with the vessel wall. For quantitative analysis of leukocyte-endothelium interactive flow assays, the distribution of leukocyte velocities can be compared across acquisitions in differing endothelial cell conditions, a crude estimate of the number of interacting leukocytes as derived from \autoref{equation:critical_velocity} is also instructive.

\section{Video acquisition}
\label{leukocytes:acquisition}
HUVECs were seeded into $\mu$-slides I\textsuperscript{0.4} (Ibidi, Munich, Germany) and treated with IL-4 (Ibidi) \SI{24}{\hour} before experimentation. The slide was placed on the microscope stage of an Axiovert 135 (Carl Zeiss, Welwyn Garden City, UK) maintained at \SI{37}{\celsius} and imaged using a 20$\times$ lens. The $\mu$-slide was connected to a syringe pump system (Harvard Aparatus, Holliston, MA, USA) to draw fluid through the chamber to give a wall shear stress of \SI{0.07}{\pascal} (0.7~$dyne~cm^{-2}$). Perfusion media (HBSS $+$ Ca$^{2+}$ $+$ Mg$^{2+}$ $+$ 0.2~\% BSA) was drawn through the chamber for a few minutes to flush thorough any cellular debris and ensure that the HUVEC monolayer was intact. Control or genetically or pharmacologically  altered HUVECs were treated with perfusion media with or without an activating stimulant or drug treatment, for \SIrange{5}{10}{\minute} under flow. \SI{5e5}{\per\milli\litre} THP-1 cells (grown in RPMI medium 1640 (Gibco BRL) plus \SI{4.5}{\gram\per\litre} D-glucose, \SI{1.5}{\gram\per\litre} sodium bicarbonate, \SI{1}{\mmol} sodium pyruvate \SI{10}{\mmol} hepes, \SI{300}{\milli\gram\per\litre} L-glutamine, \SI{0.05}{\mmol} 2-mercaptoethanol and 10~\% FCS) were added to the media with or without a secretagogue or drug treatment, to stimulate or mock stimulate HUVECs. For each condition a \SIrange{3}{6}{\minute} movie was recorded to observe any THP-1 adhesive interactions with the monolayer. Videos were captured using a QImaging Scientific CMOS (sCMOS) camera.

\section{Video processing}
\label{leukocytes:processing}
Analysis of leukocyte adhesion cascade image sequences aims to:
\begin{enumerate}
\item accurately detect the leukocytes in each frame of the video, 
\item link corresponding leukocytes over multiple frames to form trajectories, and 
\item quantify information about those trajectories.
\end{enumerate}
A variety of approaches were trialled for accurate detection, linking and quantification of leukocytes in flow assays.

Manual identification of leukocytes in each frame is impractical due to the large numbers of frames and leukocytes to be identified and the level of reproducibility required. Accurate and robust identification by automated threshold based segmentation is limited for phase contrast images, although increasingly common in fluorescence microcopy~\cite{Hand2009}.

Two prominent artifacts introduced by phase contrast microscopy are halos and shade-offs. A halo is a bright region surrounding a specimen, and the shade-off is an effect gradually reducing the intensity profile towards the centre of a large specimen. Halos are observed in this study as the result of diffracted light passing through the phase ring as well as the non-phase areas and interacting at the image plane~\cite{Yin2012}. The halo adds artificial structure to the specimen. In our setting, bright halos appear around the leukocytes with an intensity and width that depend on the local thickness of the cell. Shade-offs equalise the intensity of the inner and outer regions of large leukocytes to the same value~\cite{Otaki2000}. These two artifacts complicate the task of segmentation and hamper the use of thresholding techniques. The bright ring surrounding the adhering leukocyte in the lower left image of \autoref{figure:leukocyte_rolling-zoom} is an example of a halo, the shade-off can also be observed in this image. Phase contrast artifacts and the elongated shape of high velocity leukocytes renders blob detection via the Laplacian of the Gaussian (LoG), the difference of Gaussian (doG) and determinant of Hessian (doH) as unfeasible.

\begin{figure}[htbp!]
	\centering
	\begin{tikzpicture}[figurename=figure:leukocyte_rolling,
		zoomboxarray,
		zoomboxes right,
		zoomboxarray columns=2,
		zoomboxarray rows=2]
		\node [image node] {\includegraphics[width=0.49\textwidth]{160225_dish_1_10min_his-_00652}};
		\zoombox[magnification=3,color code=red, dashed]{0.520, 0.800}
		\zoombox[magnification=3,color code=yellow, dashed]{0.637, 0.403}
		\zoombox[magnification=3,color code=green, dashed]{0.195, 0.472}
		\zoombox[magnification=3,color code=blue, dashed]{0.587, 0.202}
	\end{tikzpicture}
	\begin{tikzpicture}[figurename=figure:leukocyte_rolling_background,
		zoomboxarray,
		zoomboxes right,
		zoomboxarray columns=2,
		zoomboxarray rows=2]
		\node [image node] {\includegraphics[width=0.49\textwidth]{160225_dish_1_10min_his-_00652_background}};
		\zoombox[magnification=3,color code=red, dashed]{0.520, 0.800}
		\zoombox[magnification=3,color code=yellow, dashed]{0.637, 0.403}
		\zoombox[magnification=3,color code=green, dashed]{0.195, 0.472}
		\zoombox[magnification=3,color code=blue, dashed]{0.587, 0.202}
	\end{tikzpicture}
	\caption[Leukocyte frame and background removal]{Image (a) is a video frame obtained from a phase contrast microscope image sequence of leukocytes in an endothelial interactive adhesion assay, with four cells identified by coloured boxes in image (b). The magnified images in (b) show leukocytes rolling over the endothelial monolayer, with four cells identified in red, yellow, green and blue boxes. An adhering leukocyte is seen in the green box. Image (c) shows the same frame after performing a contrast limited adaptive histogram equalisation (CLAHE) preprocessing step and background removal via frame differencing. In image (d) the corresponding leukocytes are shown. Note the absence of the adhering leukocyte in the green box; because it has been stationary for more than $n$ frames it forms part of the background model.}
\end{figure}

Accurately finding segmentation contours is not necessary in this study, since the exposure time of the camera and flow rate is such that a leukocyte cell appears in a video frame as an elongated streak, due to the displacement over the camera exposure duration. The length of the elongated streak is proportional to its velocity. Morphological information about the cell cannot be reliably extracted due to this optical deformation occurring. As such, the objective of the image processing approach is to detect the leukocytes and determine their position in each video frame. The velocity and acceleration can then be calculated from inter-frame positional changes. Detection can be viewed as a classification problem in which the task is to tell the presence or absence of a specific object in an image.

An approach to object detection that has been successful in many modalities is to use a Haar-features object detection classification cascade~\cite{Lienhart2002}. This is a machine-learning based approach where a cascade function is trained from a lot of positive and negative images, and  then used to detect objects in other images. 

Leukocyte detection and tracking using Haar-features object detection was performed using version 2.7 of the Python programming language, with version 2.4.10 of the OpenCV (Open Source Computer Vision) programming library. The video processing pipeline comprises three stages: 
\begin{enumerate}
\item a background removal preprocessing step,
\item detecting leukocytes using the classifier, and 
\item linking leukocytes between frames to form trajectories.
\end{enumerate}
Prior to video analysis of a data set a classifier must also be trained to detect leukocytes; a single classifier can be used for analysis of multiple videos.

\subsection{Preprocessing}
\label{leukocytes:processing:preprocessing}
A preprocessing step is performed on each frame of the video to compensate for illumination changes that may occur during the video, and any spatial illumination variation in the frame. Contrast limited adaptive histogram equalisation (CLAHE) enhances the image, and is effective even in image regions that are darker or lighter than most of the image~\cite{Ketcham1974}. The performance of leukocyte detection is also improved following CLAHE.

Histogram equalisation is an often used image enhancement method, that alters the dynamic range and contrast of an image by spreading out the most frequent intensity values. This is achieved by using a cumulative distribution function as the mapping function. Intensity levels are changed such that the peaks of the histogram are stretched and the troughs are compressed~\cite{Sasi2013}. Adaptive histogram equalisation differs from ordinary histogram equalisation in the respect that the adaptive method computes multiple histograms each corresponding to a different image region. The CLAHE algorithm works by dividing the image into smaller tiles, and applying a contrast limited local histogram equalisation. Contrast limiting equalisation minimises the amplification of noise in regions of uniform low intensity. If a histogram bin is above the specified contrast limit, pixels in that region are clipped and distributed uniformly to other bins before applying histogram equalisation. Following equalisation, artifacts in tile borders are removed by bilinear interpolation~\cite{Hummel1977}.

The CLAHE algorithm preprocessing step is applied to each frame in the video sequence to enhance the contrast between leukocytes and their background. This step helps to ensure sufficient contrast difference between leukocytes and the background for detection of leukocytes.

\subsection{Background removal}
\label{leukocytes:processing:background}
Identifying moving objects from a video sequence is a fundamental and critical task in video surveillance, traffic monitoring and analysis, human detection and tracking, and gesture recognition in human-machine interfaces~\cite{Cheung2004}. In videos that have a constant or slowly changing background a common approach to aid in identifying moving objects is using frame differencing (see \autoref{figure:leukocyte_rolling_background-image}). Moving objects can be identified as regions within a frame that differ significantly from a background model, where the background model maybe static and predefined or slowly changing.

In leukocyte endothelial flow assays the background model typically slowly changes during the recording. Fluid flow over the endothelial monolayer creates a shear stress at the endothelial surface. To minimise this shear stress endothelial cells adapt, by aligning and migrating in the direction of flow. The realignment of endothelial cells under flow is a two step process, involving the reorganisation of the cell cytoskeleton. Firstly, the endothelial cells contract and round up losing their original orientation occurring within minutes of flow being imposed. Secondly over longer time periods the cells spread and migrate in the direction of flow. Cell contraction and rounding is less pronounced in confluent endothelial cells~\cite{Wells2011}.

The rounding and contraction of the endothelial background in THP-1 interaction assay recordings complicates background removal, since a background removal algorithm is required that adjusts to longer term background changes and is robust to changes in illumination. An initial attempt at removing the background was to create a mean image, from all frames in the sequence, and calculate the absolute difference for each pixel in the image and each frame of the video. This approach did indeed enhance the moving leukocytes over the background, however as the background is not fully static, subtle changes in background illumination over the image sequence created artifacts in the images. Artifacts from endothelial contraction, firmly adhering leukocytes and debris in the flow can cause artifacts in the background subtracted image.

The approach was improved by calculating a running average background image for the duration of the video. For each frame ($F$) in the image sequence, a background image is calculated as the mean of pixels of ($n$) frames prior and proceeding the current frame. The value of a background frame ($B$) is calculated at each ($x$) and ($y$) coordinates for all time points ($t$) in the video as,
\begin{equation}
B(x,y,t) = \frac{1}{2n+1}\left(\sum_{i=1}^{n} F(x,y,t-i) + \sum_{i=0}^{n} F(x,y,t+i)\right).
\end{equation}
The absolute difference between the current frame and the background image for that frame is then then calculated, as follows,
\begin{equation}
\left|F(x,y,t) - B(x,y,t)\right|.
\end{equation}
Taking the absolute difference between the original image and a rolling averaged mean image is advantageous over a simple subtraction. The absolute difference method exposes illumination changes beyond the bit depth of the image, by maintaining negative values. The resulting pixel values were normalised in the 8-bit range 0 to 255.

A running average frame differencing method responds to gradual changes in endothelial morphology throughout the video duration and does not create significant image artifacts. The number of frames before and after the current frame, from which to calculate the average background frame is called $n$. Typically, an $n$ of 50 is effective, this can be adjusted depending on the flow rate and frame rate of the setup. The algorithm creates a background model from the closest $n$ frames, and for frames in the middle of the sequence uses $n$ frames ahead and $n$ frames behind. For frames at the start of the sequence the running average uses more frames that are after the current, and for frames at the end more frames prior to the current are used.

\subsection{Object detection}
\label{leukocytes:processing:detection}
In computer vision and image processing the task of identifying objects of a certain semantic class within a digital image is known as object detection. Face detection and pedestrian detection are especially well researched domains of object detection given their applications in photography, human computer interfaces and surveillance.

Detection of leukocytes in THP-1 interaction assays can be approached as an object detection problem. The sometimes subtle phase variation of leukocytes makes their detection via thresholding non-trivial. Thresholding and edge-detection approaches are not suitable for detection of leukocytes due largely to the halo and shade-off effects introduced by phase contrast microscopy~\cite{Yin2012}. However, a machine-learning approach for visual object recognition capable of detecting objects quickly and accurately has been implemented for leukocyte detection. This method is based on a framework originally developed for real time face detection using a set of Haar-like features~\cite{Viola2001, Lienhart2002}, and is implemented in OpenCV.

Haar wavelet feature sets are a faster alternative to image intensity features, that have been used in object detection~\cite{Papageorgiou1998}. An adaption of Haar features is Haar-like features, which considers adjacent rectangular regions at a specific location in a detection window, sums up the pixel intensities in each region and calculates the difference between these sums. This difference is then used to categorise subsections of an image (see \autoref{figure:haar_features}).

\subsubsection{Data preperation}
A cascade of boosted classifiers working with Haar-like features was trained with positive and negative example images. A positive example is an image containing a large, centered instance of the object of interest, in this case leukocytes. A negative image is an arbitrary background region with the same dimensions as the positive example. The size of each leukocyte in the video is dependent on their velocity, where leukocytes travelling at higher velocities, travel further during the exposure time of the camera and therefore appear longer. Positive images of leukocytes were selected to cover all stages of the leukocyte adhesion cascade, additionally examples with a variance in intensity and orientation were selected.

\begin{figure}[htbp]{}
	\begin{subfigure}[b]{\linewidth}
		\centering
		\includegraphics[width=0.1\linewidth]{positive_images_01}
		\includegraphics[width=0.1\linewidth]{positive_images_02}
		\includegraphics[width=0.1\linewidth]{positive_images_03}
		\includegraphics[width=0.1\linewidth]{positive_images_04}
		\includegraphics[width=0.1\linewidth]{positive_images_05}
		\includegraphics[width=0.1\linewidth]{positive_images_06}
		\includegraphics[width=0.1\linewidth]{positive_images_07}
		\includegraphics[width=0.1\linewidth]{positive_images_08}
		\caption{}
		\label{positive_images:a}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\centering
		\includegraphics[width=0.1\linewidth]{negative_images_01}
		\includegraphics[width=0.1\linewidth]{negative_images_02}
		\includegraphics[width=0.1\linewidth]{negative_images_03}
		\includegraphics[width=0.1\linewidth]{negative_images_04}
		\includegraphics[width=0.1\linewidth]{negative_images_05}
		\includegraphics[width=0.1\linewidth]{negative_images_06}
		\includegraphics[width=0.1\linewidth]{negative_images_07}
		\includegraphics[width=0.1\linewidth]{negative_images_08}
		\caption{}
		\label{negative_images:b}
	\end{subfigure}
\caption[Classifier training samples]{A sample of positive and negative images used to train the object detection classifier. Training was performed on images where the background was removed via frame differencing. The halo artifact produces a distinctive ring around leukocytes. Images in (a) are positive samples containing a single leukocyte in each image. Images in (b) do not contain leukocytes and are negative background region images.}
\label{figure:classifier_samples}
\end{figure}

The image regions for positive and negative images have the same image dimensions, where positive samples (\autoref{positive_images:a}) are views containing a leukocyte. These regions were selected manually from background removed frames, and were selected to include a range of leukocytes in differing background illumination conditions and at a variety of stages in the adhesion cascade. Negative samples (\autoref{negative_images:b}) were selected as arbitrary random image regions in background removed video frames.

To acquire a set of negative images an ImageJ macro was written to extract a set of fixed size image regions from a video at random frames and positions, see code \autoref{listing:negativesIJM}. The generated set of images from random frames and regions of the video sequence was then manually pruned to exclude any examples that happen to contain positive leukocyte instances, either wholly or partially.
\begin{lstlisting}[
	style=pseudo,
	label={listing:negativesIJM},
	caption={Generate negative samples}
	]
FOR number of negative imgaes
	CALL select a random video frame
	CALL create a rectangle: width (w), height (h), at random coordinates (x,y)
	CALL duplicate selection
	CALL save as image
END FOR
\end{lstlisting}

From the positive and negative samples a larger set of training sample objects was created using the opencv\_createsamples utility. The utility provides functionality for generation of training datatsets, writing and viewing. Samples are created by applying perspective transformations and manipulations to a positive sample, to create more samples for training. Transformations and  manipulations include: rotations around the $x$, $y$ and $z$ axis, the addition of white noise and performing inversions. A positive sample image is then superimposed on a negative sample background and a binary output file with a *.vec extension is generated.

\begin{lstlisting}[
	style=pseudo,
	label={listing:create_samples},
	caption={Create samples and merge vector files}
	]
find ./positive_images -iname "*.jpg" > positives.txt
find ./negative_images -iname "*.jpg" > negatives.txt
perl bin/createsamples.pl positives.txt negatives.txt samples 3000 "opencv_createsamples -bgcolor 0 -bgthresh 0 -maxxangle 0.05 -maxyangle 0.05 maxzangle 0.0 -maxidev 10 -w 45 -h 85"
find ./samples -name '*.vec' > samples.txt
./mergevec samples.txt samples.vec
\end{lstlisting}

In conjunction with the opencv\_createsamples utility a method written as a Perl script applies the utility in a loop, creating samples for each positive image. The output *.vec files are merged using the mergevec utility available under the MIT License written by Naotoshi Seo~\cite{Seo}. The code in \autoref{listing:create_samples} creates a *.txt containing a list of positive images and a second file for negative images. Line 3 executes the Perl script for the creation of samples based on the positives.txt and negatives.txt files and the specified parameters. The mergevec utility in line 5 creates a single samples.vec file to be used for classifier training.

\subsubsection{Classifier training}
Object detection relies on Haar-wavelet features to perform a binary classification of regions within an image. Haar-wavelet features provide a compact representation of an object class and are computationally efficient as compared to working with pixel intensities or edges directly~\cite{Papageorgiou1998}. Haar-like features are arrangements of rectangular regions within a window, the difference between sums of these areas provides a weak descriptor that is used to categorise regions in the window. The descriptor indicates a certain characteristic of a particular area of the image. The combination of multiple features is used to indicate the existence or absence of certain image characteristics such as edges or texture changes.

Object detection was performed using a set of Haar-wavelet like features cascade classifiers as proposed by Viola et al. in their paper, `Rapid Object Detection using a Boosted Cascade of Simple Features'~\cite{Viola2001}. Their approach employs machine-learning techniques to train classifiers from positive and negative images. The generated classifier can then be used to detect objects in images.

This important work (Viola et al, 2001) introduces three major contributions in object detection making rapid real time object detection possible. Firstly, they introduce the use of \emph{integral images}, which are essentially two-dimensional lookup tables. These \emph{integral images} allow more efficient calculations of the sum of rectangular areas in the image, at any position or scale. Secondly, for fast classification a method of classifiers are constructed using a small number of critical features with minimum error rates from the large number available, this is provided by the AdaBoost algorithm~\cite{Friedman2000}. Thirdly, a method was introduced which combines successively more complex classifiers in a cascade structure. The detection speed is significantly increased by focusing computational processing only on promising regions.

Training of a Haar-wavelet like object detector classifier for detection of leukocytes was achieved with the opencv\_traincascade utility. The classifier was trained on the generated samples.vec file, as shown in code \autoref{listing:train_cascasde}.

\begin{lstlisting}[
	style=pseudononumber,
	label={listing:train_cascasde},
	caption={Haar-wavelet cascasde classifier training}
	]
opencv_traincascade -data classifier -vec samples.vec -bg negatives.txt -numStages 20 -minHitRate 0.999 -maxFalseAlarmRate 0.5 -numPos 2000 -numNeg 1000 -w 45 -h 85 -mode ALL -precalcValBufSize 1024 -precalcIdxBufSize 1024
\end{lstlisting}

The opencv\_traincascade utility command line arguments pertain to: directory locations and settings, parameters for the cascade, boosted classifier parameters and Haar-like features parameters. The choice of training parameters was heavily guided by the findings of Lienhart et al, `Empirical Analysis of Detection Cascades of Boosted Classifiers for Rapid Object Detection'~\cite{Lienhart2003}. In code \autoref{listing:train_cascasde} the following command line arguments describe common locations and settings: \emph{data} is the directory name to save the classifier file, \emph{vec} the file name containing positive samples, \emph{bg} contains a file list of images of background regions to superimpose the positive samples, \emph w} and \emph{h} are the size of training samples in pixels, \emph numPos} and \emph{numNeg} determines the number of positive samples used in training at every classifier stage, \emph{precalcValBufSize} and \emph{precalcIdxBufSize} describe the size of buffer for precalculated feature indices. Making more memory available speeds up the training process.

Arguments describing the parameters for the cascade in code \autoref{listing:train_cascasde} are: \emph{numStages} determines the number of stages in the cascade to be trained. The structure of the cascade classifier is that of a degenerate decision tree, where a positive result from an initial classifier, causes the evaluation of a second classification, and a third, up to a maximum number of stages determined by \emph{numStages}. At any point a negative outcome would lead to termination and rejection of the region being classified. Training classifiers with more stages creates a more precise classifier but is more time consuming to train.

\begin{figure}[htbp!]
	\begin{subfigure}[b]{\linewidth}
		\centering
		\includegraphics[height=1.5cm,keepaspectratio]{haar_features_line}
		\caption{}
		\label{figure:haar_features:line}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\centering
		\includegraphics[height=1.5cm,keepaspectratio]{haar_features_edge}
		\caption{}
		\label{figure:haar_features:edge}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\centering
		\includegraphics[height=1.5cm,keepaspectratio]{haar_features_center_surround}
		\caption{}
		\label{figure:haar_features:center_surround}
	\end{subfigure}
	\caption[Extended Haar features]{Simple and extended set of Haar-like features. In (a), (b) and (c) features are described as line, edge and ceter surround features, respectively. Black areas have negative and white areas positive weights.}
	\label{figure:haar_features}
\end{figure}

Boosted classifier parameters are: the \emph{minHitRate}, which is the minimal desired hit rate for each stage of the classifier, and the \emph{maxFalseAlarmRate}, which is the maximal desired false alarm rate for each stage of the classifier. The final parameter \emph{mode} determines the Haar-feature set to be used in training, whether it should consist of the basic upright Haar features (\autoref{figure:haar_features:line}) or should include extended Haar features, which are a set of features rotated at a \SI{45}{\degree} angle~\cite{Lienhart2002} (\autoref{figure:haar_features:line}, \autoref{figure:haar_features:edge} and \autoref{figure:haar_features:center_surround}).

Training of the classifier is a computationally intensive process and depending on the parameter setup, object detection scenario and computer hardware can take several days to complete. Upon completion of training an extensible markup language (XML) classifier file is generated, which can be used for object detection.

\subsubsection{Leukocyte detection}
The trained classifier was used to detect objects at multiple scales in each video frame. The OpenCV detectMultiScale function was used to check if regions are likely to contain the object of interest. The function returns an array of detected regions as rectangles with $x$, $y$ coordinates and width and height.

The detectMultiScale function performs detection with a pixel-by-pixel sliding search window, which traverses the image and searches for objects in each region. For each image, the region within the window will go through the cascade classifier, to check the probability of an object being present. The search is performed at multiple scales. There are two mechanisms for scale-invariant object detection; the first is to resize the search window, the second method is to scale the image. Multiple image rescaling creates an image pyramid, by downsampling the image using neighbouring pixels~\cite{Qiao2010}.

For computational efficiency the image rescaling method has been used, but in our restricted leukocyte flow assay experimental scenario, the size of a leukocyte at the microscope magnification is fairly consistent, so only a small image rescaling is needed. In more broadly applicable tasks of object detection such as face detection, a greater size variance is indeed needed.

The cascade classifier is comprised of multiple filter stages, which are gone through at each position of the sliding window. If the search window region does not pass the threshold of a stage, the cascade classifier will reject the region as a leukocyte. If the search window region passes all stages of the classifier successfully it is classified as a candidate leukocyte, which pending further checks maybe classified as a leukocyte. The cascade filter is advantageous in the detection phase because it reduces the computational workload by rejecting regions at early stages in the cascade.

\begin{lstlisting}[
	style=pseudo,
	label={listing:object_detection},
	caption={Pseudocode for multi-scale object detection}
	]
FOR number of image scales
	downsample by one scale
	compute integral image for current scale
	FOR each shift step of the sliding detection window do
		FOR each stage in the cascade classifier do
			FOR each filter in the stage do
				filter the detection window
			END FOR
			accumulate filter outputs within this stage
			IF accumulation fails to pass per-stage threshold do
				break the for-loop and reject this window as a leukocyte
			END FOR
		END FOR
		IF this detection window passes all per-stage thresholds do
			accept this window as a leukocyte
		ELSE
			reject this window as a leukocyte
		END FOR
	END FOR
END FOR
\end{lstlisting}
The pseudocode in \autoref{listing:object_detection} describes the process of multiple size object detection, the implementation of this routine is shown as \autoref{listing:detect_multi_scale}, as implemented in OpenCV Python. In \autoref{listing:detect_multi_scale} the parameters are largely self explanatory; a maximum and minimum object size can be selected. Object regions larger or smaller than these values are ignored. The \emph{scaleFactor} parameter specifies by how much the image size is reduced at each image scale. Of particular importance is the \emph{minNeighbors} parameter, this effectively determines the object detection sensitivity. The \emph{minNeighbours} parameter is the minimum number of neighbours required for each candidate region in order that it is retrieved. Objects are usually detected at multiple scales and near other detected objects, creating neighbourhood positive regions. By increasing the \emph{minNeighbours} number, the number of false positives can be reduced, however this can have the consequence of increasing the number of false negatives. Finally the flag CV\_HAAR\_SCALE\_IMAGE, tells the routine to rescale the image rather than the search window size.

\begin{lstlisting}[
	style=pseudononumber,
	label={listing:detect_multi_scale},
	caption={OpenCV python detectMultiScale function}
	]
cv2.CascadeClassifier(cascPath).detectMultiScale(frame,scaleFactor=detectParticlesScaleFactor,minNeighbors=detectParticlesMinNeighbors,minSize=detectParticlesMinSize,maxSize=detectParticlesMaxSize,flags = cv2.cv.CV_HAAR_SCALE_IMAGE)
\end{lstlisting}

The code in \autoref{listing:detect_multi_scale} produces an array of found objects as displayed in \autoref{table:particles_features}. This gives for each particle, the frame number it is detected, the $x$ and $y$ coordinate of the upper left corner of the detection region, the width and heigh of the detection region and the $x$ and $y$ centroid of the detection region. The centroid values are calculated using the rectangle $x$ and $y$ coordinates along with width and height.

\begin{table}[htbp]
\centering
\caption{Example results table of objects detected by detectMultiScale}
\begin{tabular}{lllllll}
\toprule
frame\_no & x      & y      & w      & h      & x\_centroid & y\_centroid \\
\midrule
1         & 351    & 42     & 48     & 91     & 375.0       & 87.5        \\
1         & 1043   & 53     & 50     & 94     & 1068.0      & 100.0       \\
1         & 867    & 870    & 50     & 95     & 892.0       & 917.5       \\
2         & 24     & 288    & 49     & 92     & 48.5        & 334.0       \\
3         & 1121   & 18     & 50     & 95     & 1146.0      & 65.5        \\
\vdots    & \vdots & \vdots & \vdots & \vdots & \vdots      & \vdots      \\
\bottomrule
\end{tabular}
\label{table:particles_features}
\end{table}

\subsection{Tracking leukocytes}
\label{leukocytes:processing:tracking}
The distribution of velocities of leukocytes flowing over an endothelial monolayer can be used to study interaction events associated with an inflammatory response. Determination of leukocyte velocities requires detection of leukocyte positions in each video frame (as described in \autoref{leukocytes:processing:detection}). In addition to this, a method is needed to link leukocytes over multiple frames. Tracking of leukocytes over multiple consecutive video frames is used to collect trajectory data, including the instantaneous velocity and acceleration, which are essential to the study of leukocyte interaction events. The linking of leukocytes into trajectories is achieved by a particle tracking algorithm.

Particle tracking algorithms analyse sequential video frames and record the movement of particles or objects over those frames. This has applications in human-computer interaction, security, surveillance, traffic control and medical imaging. Two commonly used algorithms are meanshift and camshift tracking. These methods use an iterative localisation procedure based on the maximization of a similarity measure~\cite{Comaniciu2000}.

In a biological context particle tracking tends to focus on scenarios where the motion between frames is effectively Brownian. Two common software packages for particle tracking of particles with a Brownian like motion are \emph{TrackMate} in ImageJ and \emph{TrackPy} in Python. These were found to be suboptimal when applied to tracking leukocytes in an interaction assay where the experimental protocol ensures a linear flow direction.

Since the motion of leukocytes was always in the direction of fluid flow, a tracking protocol was created and here described to exploit this. Leukocyte tracking is a video post-processing step, following detection of leukocyte positions in each video frame, they are linked by particle ID values over multiple frames into trajectories. The procedure for linking of leukocytes involves a loop to iterate through every found leukocyte and identify the leukocyte in proceeding frames. The final stage of leukocyte tracking is the filtering of trajectories.

\subsubsection{Particle linking}
Each object detected represents one row in \autoref{table:particles_features}. These objects are linked using a for-loop that iterates through each row in \autoref{table:particles_features} and attempts to identify and assign corresponding objects in later frames the same ID. Particle linking works on the premise that particles move in the direction of flow, and therefore particles in later frames will be within a narrow range of $x$ values and will have $y$ values greater than the original. Particles are linked over sequential frames according to the minimal displacement in $y$ value, particle IDs are then matched to form a trajectory.

Prior to applying this particle linking routine, the array of found objects (\autoref{table:particles_features}) is sorted by frame number and then by the $y$-coordinates of objects in each frame. In the first frame of the video sequence with detected objects present, the objects are assigned a sequential numerical ID depending on their $y$-coordinate value. From the initial setup with IDs assigned in one frame, numerical IDs can be assigned to all other leukocytes in the data frame, as shown in \autoref{listing:tracking_loop}. 

\begin{lstlisting}[
	style=pseudo,
	label={listing:tracking_loop},
	caption={Particle linking }
	]
ASSIGN ID to objects in frame with first detected object by y value
FOR each detected object
	IF particle_ID == NULL
		GET max particle_ID in particles table
		ASSIGN particle_ID as max(particle_ID) + 1
		GET particles in lookahead frames within x range and larger y value
		IF particles are found
			ASSIGN particle_ID as max(particle_ID) + 1
	ELSE particle_ID != NULL
		GET particles in lookahead frames within x range and larger y value
		IF particles are found
			ASSIGN particle_ID
END FOR
\end{lstlisting}

To summarise \autoref{listing:tracking_loop}, for each detected object (row in \autoref{table:particles_features}), if it does not have an ID assigned, it is assigned the next highest particle ID, following this a function looks in proceeding frames for leukocytes to link by assigning the same ID. If the leukocyte has an ID already assigned, then proceeding frames will be searched and leukocytes linked by their ID. In this way after iterating through all the rows, every detected leukocyte in every frame of the video has an ID assigned to it. A parameter specifies how many frames to look ahead when linking particles into trajectories, typically 2 frames are searched. This means that if a particle is not detected in one frame then the trajectory is not broken.

\begin{figure}[htbp]{}
	\centering
	\begin{subfigure}[b]{0.49\linewidth}
		\includegraphics[width=\linewidth]{160225_dish_1_10min_his-_02338_tracking_1}
		\caption{}
		\label{figure:video_processing:particle_linking_1}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\linewidth}
		\includegraphics[width=\linewidth]{160225_dish_1_10min_his-_02339_tracking_2}
		\caption{}
		\label{figure:video_processing:particle_linking_2}
	\end{subfigure}
\caption[Leukocyte particle linking]{An example of a detected leukocyte particle being linked over two consecutive frames. Image (a) shows the original detected leukocyte particle to be linked in the first frame. Image (b) is the next consecutive frame, the search area is highlighted as the grey region and the 3 candidate particles for linking are annotated with a box. These candidate particles are ranked in order of their distance from the original particle and linking performed for the closest particle to the orignal particle.}
\label{figure:video_processing:particle_linking}
\end{figure}

An example of particle linking is shown in \autoref{figure:video_processing:particle_linking}. A leukocyte is detected, the white box in \autoref{figure:video_processing:particle_linking_1} and the proceeding frame searched within a range $x$ values. An $x$ coordinate range was typically chosen to correspond to half the width of the search window or $\pm$ 30 pixels. The $y$ coordinate range searched was restricted to a range greater than the $y$ centroid of the original particle. The search area can be seen as the grey shaded area in \autoref{figure:video_processing:particle_linking_2}, in which three particles were found. These were ranked 1, 2 and 3 in order of their distance from the original particle, and labelled for illustration in \autoref{figure:video_processing:particle_linking_2}, the closest particle was then chosen to be linked with the original. This method does not make any assumptions about particle velocity between frames, and therefore is capable of tracking particles that are rapidly accelerating, as they interact with endothelial monolayer.

\subsubsection{Trajectories}
Having assigned and linked particles by numerical ID, trajectories can be cleaned and calculations performed. A minimum trajectory length is specified to remove detected objects that appear in less than $n$ number of frames. This helps to remove very short trajectories that may exist for example as incorrectly detected false positives being linked together. A minimum trajectory length of 10 frames has been used to remove short trajectories. Similarly, trajectories appearing in the first and last frames of the video sequence have been removed since they are not complete and may continue beyond the duration of the recording. Following this the results are sorted according to the particle ID values and frame number column. Each video frame is annotated with coloured boxes showing a unique trajectory with a particle ID number next to the box, as in \autoref{figure:leukocyte_rolling_detected-image} and \autoref{figure:leukocyte_rolling_detected-zoom}. Displaying the trajectory number allows cross referencing with the output results table.

Following the linking of particles into trajectories, information about the trajectories was calculated. As the $x$ and $y$ displacement of a particle linked over consecutive frames is known, using Pythagoras's theorem the Cartesian displacement was calculated. From this and knowing the frame rate of the camera the instantaneous velocity and acceleration of the particle was calculated.

\begin{figure}[htbp!]
	\centering
	\begin{tikzpicture}[figurename=figure:leukocyte_rolling_detected,
		zoomboxarray,
		zoomboxes right,
		zoomboxarray columns=2,
		zoomboxarray rows=2]
		\node [image node] {\includegraphics[width=0.49\textwidth]{160225_dish_1_10min_his-_00652_detected}};
		\zoombox[magnification=3,color code=red, dashed]{0.320, 0.900}
		\zoombox[magnification=3,color code=yellow, dashed]{0.637, 0.403}
		\zoombox[magnification=3,color code=green, dashed]{0.195, 0.472}
		\zoombox[magnification=3,color code=blue, dashed]{0.587, 0.202}
	\end{tikzpicture}
	\caption[Leukocyte tracking]{Image (a) is a video frame obtained from a phase contrast microscope image sequence of leukocytes in an endothelial interactive adhesion assay with the object detection and tracking protocol applied. The frame has been annotated with trajectories displayed in a coloured box with a number. In the magnified images in (b) leukocytes rolling over the endothelial monolayer can be seen in the red, yellow and blue boxes, an adhering leukocyte is seen in the green box.}
\end{figure}

\section{Performance evaluation}
\label{leukocytes:validation}
Two approaches were taken to establish the effectiveness of the leukocyte detection and tracking methodology, described in \autoref{leukocytes:processing}. An assessment of the leukocyte object classification scheme was performed, with the additional capability of being able to perform parameter optimisation. Further to this, the accuracy of the tracking protocol was assessed with reference to a manual set of tracked leukocytes.

\subsection{Object detection}
\label{leukocytes:validation:object_detection}
The object detection method, described in section \autoref{leukocytes:processing:detection} was validated with reference to a gold standard set of detected leukocytes. The gold standard reference set was generated from 90 frames, selected at random from 12 videos and 2 experiments. In each frame the $x$ and $y$ coordinate centroids of leukocyte objects were manually recorded, giving a total of 1078 leukocytes.

Selection of objects appropriate for classification is not trivial, since leukocytes travel at a range of velocities, and their profile or streak length is dependent on their velocity. The scope of this detection and tracking algorithm is to evaluate the slower leukocytes, which may be interacting with the endothelial monolayer. Higher velocity trajectories, may only exist in several frames and their detection and tracking would be more error prone. Making a judgement as to what length of object is appropriate for classification is difficult. The classifier was trained with objects in images of size 45 pixels by 85 pixels, this was used as a guide to the maximum object size in the gold standard set.

Leukocytes partially in frame or within one detection window of the frame edge were not labelled since the classifier requires the full object and background for detection. It could therefore be argued that this performance evaluation may overestimate the recall value. However, the detection of leukocyte in the fist or final are less significant than consistent detection of frames in the middle of a trajectory.

Having generated a gold standard reference coordinate set, the performance of the automated Haar-like features object detection was compared relative to the gold standard. Evaluation of the binary classifier involves classification of true positives, false positives and false negatives, of the automated coordinate set relative to the gold standard coordinate set. This was done for each frame of the 90 frames in the reference set, and an annotated image set produced, as is shown in \autoref{figure:leukocyte_rolling_validation-image}. A range of classification errors can occur depending on the leukocytes present in the local image region being analysed. Faint longer streaks may be incorrectly identified as leukocytes, this is demonstrated by the blue rectangle in \autoref{figure:leukocyte_rolling_validation-zoom}. Alternatively, leukocytes with unusual intensity variations and overlapping with other foreground objects can lead to detection of false negatives, as shown by the red rectangle of \autoref{figure:leukocyte_rolling_validation-zoom}.

\begin{figure}[htbp!]
	\centering
	\begin{tikzpicture}[figurename=figure:leukocyte_rolling_validation,
		zoomboxarray,
		zoomboxes right,
		zoomboxarray columns=1,
		zoomboxarray rows=1]
		\node [image node] {\includegraphics[width=0.49\textwidth]{160212_IL4+PMA-_03615_validation}};
		\zoombox[magnification=3.8,color code=yellow, dashed]{0.785, 0.73}
	\end{tikzpicture}
	\caption[Object detection performance]{Image (a) is an automatically annotated video frame, showing the performance of the object detection method. With reference to the gold standard classification, objects within green rectangles are true positives, blue rectangles are false positives and red rectangles false negatives. The magnified images in (b) shows a region containing a true positive, false positive and false negative.}
\end{figure}

Determining true positives, false positives and false negatives was achieved with a script to correlate particles found by the Haar-like features object detection to the gold standard classification for each frame. Code logic is shown in \autoref{listing:object_detection_performance}. In each of the 90 validation frames the labelled gold standard coordinate set was given an initial classification of false negatives. Following this, the automated object detection was run, generating a second set of object coordinates. The generated coordinate set are all initially labelled as false positives. A default state of false positives in the automated set, and false negatives in the gold standard set is assumed. True positives are found by searching for corresponding coordinates between the automated and gold standard sets. For each coordinate position in the automated leukocyte coordinates, if a corresponding object can be found in the table of gold standard coordinates then it is labelled as a true positive, and the object in the gold standard table removed. Objects are matched if their centroid coordinates are within the same detection window size area. The final stage, having labelled false positives, false negatives and true positives is to concatenate the automatically detected coordinate set with the gold standard set, the tables are then sorted according to their $y$ values. From the number of true positives, false positives and false negatives the true positive rate or sensitivity and the true negative rate or specificity can be calculated.

\begin{lstlisting}[
	style=pseudo,
	label={listing:object_detection_performance},
	caption={Object detection performance relative to gold standard}
	]
FOR each frame
	GET gold_standard coordinates
	LABEL all gold_standard_objects as FN
	RUN automated object detection
	LABEL all automated_objects as FP
	FOR each row in automated_objects
		IF particle exists +/- w/2 and +/- h/2 of any gold_standard_objects
			LABEL object as TP
			DELETE row from gold_standard_objects table
	END FOR
	CONCAT gold_standard_objects and automated_objects
	SORT by y-coordinate
END FOR
\end{lstlisting}

An important parameter to optimise in Haar-like features object detection is the \emph{minNeighbors} parameter, described in \autoref{leukocytes:processing:detection}. This parameter specifies how many neighbours each candidate rectangle should have to retain it, thereby acting as a discrimination threshold. The choice of a \emph{minNeighbors} parameter balances the recall and the precision rate of the classification system. To find the optimal choice of \emph{minNeighbrs} parameter the validation protocol in \autoref{listing:object_detection_performance}, was run at every integer parameter value between 0 and 300. The mean precision and recall over the 90 image and 1078 leukocyte validation image set was plotted in \autoref{figure:pr_roc:roc}, along with the F1 score. A maximal F1 score was achieved with a \emph{minNeighbors} parameter of 160. However, a value of 140 was was used in video analysis to favour a higher recall than precision, since for trajectory tracking high recall is more important than precision. A false negative is more problematic than a false positive, because a false negative can result in a trajectory being broken. On the other hand false positives usually do not correlate with any particles in proceeding frames so are expunged from the data set during trajectory linking. Using a \emph{minNeighbors} parameter value of 140 a recall of 0.90 and precision of 0.81 was achieved. This value is displayed as a dashed line in \autoref{figure:pr_roc:pr_curve}, and a red dot in \autoref{figure:pr_roc:roc}.

\begin{figure}[htbp]{}
	\centering
	\begin{subfigure}[b]{0.72\linewidth}
		\includegraphics[width=\linewidth]{pr_curves}
		\caption{}
		\label{figure:pr_roc:pr_curve}
	\end{subfigure}
	\begin{subfigure}[b]{0.74\linewidth}
		\includegraphics[width=\linewidth]{roc}
		\caption{}
		\label{figure:pr_roc:roc}
	\end{subfigure}
\caption[Precision, recall and F1 score over parameter range]{Plot (a) shows the precision, recall and F1 curves of the automated object classifier over a 90 image validation set, for the \emph{minNeighbours} parameter in a range from 0 to 300. The dashed line is the selected \emph{minNeighbors} parameter of 140. The precision-recall curve in (b) shows the relationship between precision and recall over the parameter range, where the red dot is the chosen parameter value of 140.}
\label{figure:pr_roc}
\end{figure}

\subsection{Tracking}
\label{leukocytes:validation:tracking}
A comprehensive evaluation of leukocyte endothelial interaction assay analysis should include a systematic performance evaluation of the tracking approach. Systems tracking single objects can be evaluated with a straightforward benchmarking approach. However, for multiple object tracking systems as in leukocyte endothelial interaction assays, there is no generally agreed upon evaluation procedure.

Bernardin et al., 2008~\cite{Bernardin2008} present a method to detect the basic types of errors produced by multiple object trackers. They introduce two metrics, multiple object tracking precision (MOTP) and multiple object tracking accuracy (MOTA). These metrics express the tracking procedures ability to estimate object positions and to follow objects consistently over time.

The multiple object tracking precision (MOTP), was calculated as:
\begin{equation}
	MOTP=\frac{\sum_{i,t}d_{t}^{i}}{\sum_{t}c_{t}},
\end{equation}
where, ($d$) is the distance between a matched pair of automatically tracked and gold standard particles. This metric represents the ability of the tracker to precisely find object positions, calculated as the average error in position between the automated classifier and a gold standard set. To calculate this 864 leukocyte positions were recorded in 200 consecutive video frames. For each matched gold standard and automated leukocyte pair the euclidean distance between the gold standard and automated position was calculated. A MOTP value of 3.5 pixels was achieved from this, showing a high degree of precision in estimating leukocyte positions.

A second metric the multiple object tracking accuracy (MOTA), was calculated from:
\begin{equation}
	MOTA=1-\frac{\sum_{t}(m_t+fp_t+mme_t)}{\sum_{t}g_{t}},
\end{equation}
where, ($m_t$), ($fp_t$) and ($mme_t$) are the number of misses, of false positives and of mismatches, respectively, for time $t$. A miss is an object that the tracking method failed to record, a false positive is an incorrectly tracked particle, that is not actually an object and a mismatch is a particle that is incorrectly reassigned a new ID whilst tracking. These three basic error types are summed to give an error ratio and the resulting tracking accuracy.

To calculate a MOTA value the number of objects, misses, false positives and mismatches were counted in each frame of 200 consecutive video frames. A total of 846 objects were recorded, with 51 misses, 13 false positives and 0 mismatches and a MOTA value of 0.92 was achieved.

A high MOTP and MOTA suggest that the detection and tracking methodology presented in \autoref{leukocytes:processing} is well suited for the task of tracking leukocytes. The MOTP and MOTA values of 3.5 pixels and 0.92 were achieved from a video of unstimulated endothelial cells. The MOTA value may be reduced in videos with more leukocyte endothelial interaction, leading to more slow particles and therefore greater probability of occlusion of leukocytes.

\section{Summary}
\label{leukocytes:summary}
This chapter presented a method to detect and track leukocytes in interactive adhesion assays using Haar-like feature object detection and a custom tracking algorithm. In \autoref{leukocytes:introduction} an introduction is given, describing the physiological relevance of shear stress and how this is calculated in an \emph{in vitro} flow assay, along with a description of methods of quantitative analysis, and finally an explanation and formula to calculate the maximum velocity of rolling leukocytes. In \autoref{leukocytes:acquisition} the experimental method used to perform these \emph{in vitro} flow assays is described.

In \autoref{leukocytes:processing} the processing of acquired videos is described from pre-processing to enhance contrast and remove background, to feature detection, linking and leukocyte tracking. 

In \autoref{leukocytes:validation} a comprehensive evaluation of the leukocyte tracking method is described. The Haar-like feature object detection method is evaluated by comparing to a hand-labelled gold standard and the accuracy measured. Parameter optimisation is performed with reference to this gold standard dataset. Leukocyte tracking was evaluated using two metrics described by Bernardin et al., 2008~\cite{Bernardin2008}. The MOTP assessed the spatial precision of leukocyte detection, and found the a MOTP value of 3.5 pixels. The accuracy of the tracking protocol was evaluated using the MOTA metric and a value of 0.92 found.

The methodology described here represents a precise and accurate way to hugely increase the quantitative yield from interactive adhesion flow assays with leukocytes, and can therefore be applied to give higher level biological insight.
